<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>Hasor DataWay 简化后台开发</title>
    <url>/2020/05/01/Hasor%20DataWay%20%E7%AE%80%E5%8C%96%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/</url>
    <content><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><blockquote>
<p>五一小长假终于来了，在放假之前我就做好打算，在家宅着与代码为伴，学一些自己感兴趣的东西。偶然看见一个介绍Hasor Dataway的文章，能够简化后端繁琐的开发，抛弃controller，service，mapper，dao等繁琐的工作，直接将数据更直接的展示出来。所以我也就只是介绍快速搭建一个开发环境，以及一些基本的使用，不求甚解，只是纯粹出于个人的兴趣，以后有时间说不定再研究一下。</p>
</blockquote>
<p><code>Dataway文档地址</code>：<a href="https://www.hasor.net/web/index.html" target="_blank" rel="noopener">https://www.hasor.net/web/index.html</a></p>
<p><code>Hasor的仓库地址</code>:    <a href="https://gitee.com/zycgit/hasor.git" target="_blank" rel="noopener">https://gitee.com/zycgit/hasor.git</a></p>
<h3 id="快速入门"><a href="#快速入门" class="headerlink" title="快速入门"></a>快速入门</h3><h4 id="pom-xml"><a href="#pom-xml" class="headerlink" title="pom.xml"></a>pom.xml</h4><pre><code class="xml">&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;
&lt;/dependency&gt;

&lt;dependency&gt;
    &lt;groupId&gt;mysql&lt;/groupId&gt;
    &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;
    &lt;scope&gt;runtime&lt;/scope&gt;
&lt;/dependency&gt;

&lt;dependency&gt;
    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;
    &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt;
&lt;/dependency&gt;

&lt;!-- 引入依赖 --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;net.hasor&lt;/groupId&gt;
    &lt;artifactId&gt;hasor-spring&lt;/artifactId&gt;
    &lt;version&gt;4.1.4&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
    &lt;groupId&gt;net.hasor&lt;/groupId&gt;
    &lt;artifactId&gt;hasor-dataway&lt;/artifactId&gt;
    &lt;version&gt;4.1.4&lt;/version&gt;
&lt;/dependency&gt;</code></pre>
<h4 id="application-yml"><a href="#application-yml" class="headerlink" title="application.yml"></a>application.yml</h4><pre><code class="yaml"># 配置我的连接的通用属性
alicloud:
  host: xxx
  username: xxx
  password: xxx

spring:
  datasource:
    #    最好用的数据源，速度最快 HikariCP
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://${alicloud.host}:3306/community
    username: ${alicloud.username}
    password: ${alicloud.password}

# 启用 Dataway 功能（默认不启用）
HASOR_DATAQL_DATAWAY: true
  # 开启 ui 管理功能（注意生产环境必须要设置为 false，否则会造成严重的生产安全事故）
HASOR_DATAQL_DATAWAY_ADMIN: true
  # （可选）API工作路径
HASOR_DATAQL_DATAWAY_API_URL: /api/
  # （可选）ui 的工作路径，只有开启 ui 管理功能后才有效
HASOR_DATAQL_DATAWAY_UI_URL: /interface-ui/</code></pre>
<h4 id="初始化sql"><a href="#初始化sql" class="headerlink" title="初始化sql"></a>初始化sql</h4><ul>
<li><code>sql</code>在<code>hasor-dataway</code>的<code>META-INF/hasor-framework</code>下可以找到</li>
</ul>
<pre><code class="mysql">CREATE TABLE `interface_info` (
    `api_id`          int(11)      NOT NULL AUTO_INCREMENT   COMMENT &#39;ID&#39;,
    `api_method`      varchar(12)  NOT NULL                  COMMENT &#39;HttpMethod：GET、PUT、POST&#39;,
    `api_path`        varchar(512) NOT NULL                  COMMENT &#39;拦截路径&#39;,
    `api_status`      int(2)       NOT NULL                  COMMENT &#39;状态：0草稿，1发布，2有变更，3禁用&#39;,
    `api_comment`     varchar(255)     NULL                  COMMENT &#39;注释&#39;,
    `api_type`        varchar(24)  NOT NULL                  COMMENT &#39;脚本类型：SQL、DataQL&#39;,
    `api_script`      mediumtext   NOT NULL                  COMMENT &#39;查询脚本：xxxxxxx&#39;,
    `api_schema`      mediumtext       NULL                  COMMENT &#39;接口的请求/响应数据结构&#39;,
    `api_sample`      mediumtext       NULL                  COMMENT &#39;请求/响应/请求头样本数据&#39;,
    `api_create_time` datetime     DEFAULT CURRENT_TIMESTAMP COMMENT &#39;创建时间&#39;,
    `api_gmt_time`    datetime     DEFAULT CURRENT_TIMESTAMP COMMENT &#39;修改时间&#39;,
    PRIMARY KEY (`api_id`)
) ENGINE=InnoDB AUTO_INCREMENT=0 DEFAULT CHARSET=utf8mb4 COMMENT=&#39;Dataway 中的API&#39;;


CREATE TABLE `interface_release` (
    `pub_id`          int(11)      NOT NULL AUTO_INCREMENT   COMMENT &#39;Publish ID&#39;,
    `pub_api_id`      int(11)      NOT NULL                  COMMENT &#39;所属API ID&#39;,
    `pub_method`      varchar(12)  NOT NULL                  COMMENT &#39;HttpMethod：GET、PUT、POST&#39;,
    `pub_path`        varchar(512) NOT NULL                  COMMENT &#39;拦截路径&#39;,
    `pub_status`      int(2)       NOT NULL                  COMMENT &#39;状态：0有效，1无效（可能被下线）&#39;,
    `pub_type`        varchar(24)  NOT NULL                  COMMENT &#39;脚本类型：SQL、DataQL&#39;,
    `pub_script`      mediumtext   NOT NULL                  COMMENT &#39;查询脚本：xxxxxxx&#39;,
    `pub_script_ori`  mediumtext   NOT NULL                  COMMENT &#39;原始查询脚本，仅当类型为SQL时不同&#39;,
    `pub_schema`      mediumtext       NULL                  COMMENT &#39;接口的请求/响应数据结构&#39;,
    `pub_sample`      mediumtext       NULL                  COMMENT &#39;请求/响应/请求头样本数据&#39;,
    `pub_release_time`datetime     DEFAULT CURRENT_TIMESTAMP COMMENT &#39;发布时间（下线不更新）&#39;,
    PRIMARY KEY (`pub_id`)
) ENGINE=InnoDB AUTO_INCREMENT=0 DEFAULT CHARSET=utf8mb4 COMMENT=&#39;Dataway API 发布历史。&#39;;

create index idx_interface_release on interface_release (pub_api_id);</code></pre>
<h4 id="将Datasource注入Hasor容器"><a href="#将Datasource注入Hasor容器" class="headerlink" title="将Datasource注入Hasor容器"></a>将Datasource注入Hasor容器</h4><ul>
<li>在项目目录下建一个<code>hasor目录</code></li>
</ul>
<pre><code class="java">package xxx.hasor;

import net.hasor.core.ApiBinder;
import net.hasor.core.DimModule;
import net.hasor.db.JdbcModule;
import net.hasor.db.Level;
import net.hasor.spring.SpringModule;
import org.springframework.stereotype.Component;

import javax.annotation.Resource;
import javax.sql.DataSource;

/**
 * @author : eyestarrysky
 * @date : Created in 2020/5/1
 */
@DimModule
@Component
public class HasorModule implements SpringModule {

    @Resource
    private DataSource dataSource;

    @Override
    public void loadModule(ApiBinder apiBinder) throws Throwable {
        apiBinder.installModule(new JdbcModule(Level.Full, this.dataSource));
    }
}
</code></pre>
<h4 id="SpringBoot启动类开启Hasor注解"><a href="#SpringBoot启动类开启Hasor注解" class="headerlink" title="SpringBoot启动类开启Hasor注解"></a>SpringBoot启动类开启Hasor注解</h4><pre><code class="java">package xxx;

import net.hasor.spring.boot.EnableHasor;
import net.hasor.spring.boot.EnableHasorWeb;
import org.springframework.boot.SpringApplication;
import org.springframework.boot.autoconfigure.SpringBootApplication;

@EnableHasor
@EnableHasorWeb
@SpringBootApplication
public class DatawayApplication {

    public static void main(String[] args) {
        SpringApplication.run(DatawayApplication.class, args);
    }

}</code></pre>
<h4 id="项目启动"><a href="#项目启动" class="headerlink" title="项目启动"></a>项目启动</h4><pre><code class="verilog"> _    _                        ____              _
| |  | |                      |  _ \            | |
| |__| | __ _ ___  ___  _ __  | |_) | ___   ___ | |_
|  __  |/ _` / __|/ _ \| &#39;__| |  _ &lt; / _ \ / _ \| __|
| |  | | (_| \__ \ (_) | |    | |_) | (_) | (_) | |_
|_|  |_|\__,_|___/\___/|_|    |____/ \___/ \___/ \__|</code></pre>
<ul>
<li>项目启动成功，访问<code>http://localhost:8080/interface-ui/</code>即可</li>
</ul>
<h3 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h3><ul>
<li>接口面板</li>
</ul>
<p><img src="http://qiniu.eyestarrysky.top/dataway-console.png" alt="找不到"></p>
<ul>
<li>新增接口，右边几个按钮分别为<code>save</code>，<code>execute</code>, <code>test</code>, <code>publish</code></li>
</ul>
<p><img src="http://qiniu.eyestarrysky.top/dataway-new-interface.png" alt="找不到"></p>
]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>DataQL</tag>
      </tags>
  </entry>
  <entry>
    <title>LeetCode题解-102.二叉树的层序遍历</title>
    <url>/2020/05/14/LeetCode%E9%A2%98%E8%A7%A3-102.%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B1%82%E5%BA%8F%E9%81%8D%E5%8E%86/</url>
    <content><![CDATA[<h3 id=""><a href="#" class="headerlink" title=""></a></h3><h3 id="102-二叉树的层序遍历"><a href="#102-二叉树的层序遍历" class="headerlink" title="102.二叉树的层序遍历"></a>102.二叉树的层序遍历</h3><ul>
<li>给你一个二叉树，请你返回其按 层序遍历 得到的节点值。 （即逐层地，从左到右访问所有节点）。</li>
</ul>
<pre><code class="markdown">示例：
二叉树：[3,9,20,null,null,15,7],
    3
   / \
  9  20
    /  \
   15   7
返回其层次遍历结果：

[
  [3],
  [9,20],
  [15,7]
]</code></pre>
<h4 id="深度度优先遍历-DFS"><a href="#深度度优先遍历-DFS" class="headerlink" title="深度度优先遍历-DFS"></a>深度度优先遍历-DFS</h4><pre><code class="java">class Solution {
    List&lt;List&lt;Integer&gt;&gt; depthList = new ArrayList&lt;&gt;();

    /**
     * 解法一: 采用深度优先遍历
     * @param root 根节点
     * @return List&lt;List&lt;Integer&gt;&gt;
     */
    public List&lt;List&lt;Integer&gt;&gt; levelOrderUseDFS(TreeNode root) {
        if (null == root) {
            return depthList;
        }
        recursive(root, 0);
        return depthList;
    }

    public void recursive(TreeNode node, int depth) {
        if (depthList.size() == depth) {
            //这里使用链表，不需要扩容
            depthList.add(new LinkedList&lt;&gt;());
        }
        depthList.get(depth).add(node.val);
        if (null != node.left) {
            recursive(node.left, depth + 1);
        }
        if (null != node.right) {
            recursive(node.right, depth + 1);
        }
    }

}</code></pre>
<h4 id="广度优先遍历-BFS"><a href="#广度优先遍历-BFS" class="headerlink" title="广度优先遍历-BFS"></a>广度优先遍历-BFS</h4><pre><code class="java">     /**
     * 解法二: 采用深度优先遍历
     * @param root 根节点
     * @return List&lt;List&lt;Integer&gt;&gt;
     */
    public List&lt;List&lt;Integer&gt;&gt; levelOrderUseBFS(TreeNode root) {
        List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;();
        if (null == root) {
            return res;
        }
        Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;();
        queue.offer(root);
        while (!queue.isEmpty()) {
            int size = queue.size();
            List&lt;Integer&gt; list = new LinkedList&lt;&gt;();
            //内循环取出位于二叉树同一层的元素
            for (int i = 0; i &lt; size; i++) {
                TreeNode cur = queue.remove();
                list.add(cur.val);
                if (null != cur.left) {
                    queue.add(cur.left);
                }
                if (null != cur.right) {
                    queue.add(cur.right);
                }
            }
            res.add(list);
        }
        return res;
    }</code></pre>
]]></content>
      <categories>
        <category>LeetCode</category>
      </categories>
      <tags>
        <tag>LeetCode</tag>
        <tag>数据结构</tag>
        <tag>算法</tag>
      </tags>
  </entry>
  <entry>
    <title>使用jetcache来操作缓存</title>
    <url>/2020/04/27/%E4%BD%BF%E7%94%A8jetcache%E6%9D%A5%E6%93%8D%E4%BD%9C%E7%BC%93%E5%AD%98/</url>
    <content><![CDATA[<h3 id="Jetcache前言"><a href="#Jetcache前言" class="headerlink" title="Jetcache前言"></a>Jetcache前言</h3><ul>
<li><code>git</code>地址:  <a href="https://github.com/alibaba/jetcache/" target="_blank" rel="noopener">https://github.com/alibaba/jetcache/</a></li>
</ul>
<p>​        <strong>因为之前项目的原因接触过jecache，但是没有好好整理，今天闲下来，悉心整理了下，并看了下文档，学了下自动刷新缓存，感觉这个挺适合用来更新首页轮播图，通栏的。</strong></p>
<h3 id="基本配置（Spring-Boot"><a href="#基本配置（Spring-Boot" class="headerlink" title="基本配置（Spring Boot)"></a>基本配置（Spring Boot)</h3><h4 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h4><h5 id="pom-xml"><a href="#pom-xml" class="headerlink" title="pom.xml"></a>pom.xml</h5><pre><code class="xml">&lt;!-- jetCache  --&gt;
&lt;dependency&gt;
    &lt;groupId&gt;com.alicp.jetcache&lt;/groupId&gt;
    &lt;artifactId&gt;jetcache-starter-redis&lt;/artifactId&gt;
    &lt;version&gt;2.6.0&lt;/version&gt;
&lt;/dependency&gt;</code></pre>
<h5 id="application-yml"><a href="#application-yml" class="headerlink" title="application.yml"></a>application.yml</h5><pre><code class="yml">#jetcache
# @see com.alicp.jetcache.autoconfigure.JetCacheProperties
jetcache:
  # 统计间隔，默认0：表示不统计
  statIntervalMinutes: 1
  # areaName是否作为缓存key前缀，默认True
  areaInCacheName: false
  local:
    default:
      # 已支持可选：linkedhashmap、caffeine
      type: linkedhashmap
      # key转换器的全局配置，当前只有：fastjson, @see com.alicp.jetcache.support.FastjsonKeyConvertor
      keyConvertor: fastjson
      # 每个缓存实例的最大元素的全局配置，仅local类型的缓存需要指定
      limit: 100
      # jetcache2.2以上，以毫秒为单位，指定多长时间没有访问，就让缓存失效，当前只有本地缓存支持。0表示不使用这个功能，指定30秒后失效
      expireAfterAccessInMillis: 30000
  remote:
    default:
      type: redis
      keyConvertor: fastjson
      valueEncoder: java
      valueDecoder: java
      poolConfig:
        minIdle: 5
        maxIdle: 20
        maxTotal: 50
      host: ${redis.host}
      port: 6379
      password: ${redis.password}</code></pre>
<h5 id="启动类"><a href="#启动类" class="headerlink" title="启动类"></a>启动类</h5><pre><code class="java">@SpringBootApplication
@EnableMethodCache(basePackages = &quot;com.company.mypackagee&quot;)
@EnableCreateCacheAnnotation
public class Application extends SpringBootServletInitializer {

    public static void main(String[] args) {
        SpringApplication.run(Application.class);
    }
}</code></pre>
<h3 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h3><ul>
<li><p>下面例子以操作<code>User</code>为例<br><code>user.java</code></p>
<pre><code class="java">@TableName(value = &quot;user&quot;)
@Data
public class User implements Serializable {
    private static final long serialVersionUID = 738881519595997996L;
    /**主键**/
    @NotNull(message = &quot;主键不能为空&quot;)
    private Long id;
    /**姓名**/
    @NotBlank(message = &quot;名字不能为空&quot;)
    @Length(min = 1, message = &quot;名字至少1个字&quot;)
    private String name;
    /**手机号**/
    @NotBlank(message = &quot;手机号不能为空&quot;)
    @Size(max = 11, message = &quot;手机号最长11位&quot;)
    @Pattern(regexp = &quot;^1\\d+$&quot;, message = &quot;手机号格式不正确&quot;)
    private String phone;
    /**电子邮件**/
    @NotBlank(message = &quot;邮箱不能为空&quot;)
    @Email(message = &quot;电子邮件格式不正确&quot;)
    @Length(max = 30, message = &quot;邮箱长度不能超过30!&quot;)
    private String email;
    /**自我介绍**/
    private String aboutme;
    /**加密密码**/
    private String passwd;
    /**头像图片**/
    private String avatar;
    /**1:普通用户，2:房产经纪人**/
    private Integer type;
    /**创建时间**/
    private Date createTime;
    /**是否启用,1启用，0停用**/
    private Integer enable;
    /**所属经纪机构**/
    private Integer agencyId;
}</code></pre>
</li>
</ul>
<h4 id="基于注解实现方法缓存"><a href="#基于注解实现方法缓存" class="headerlink" title="基于注解实现方法缓存"></a>基于注解实现方法缓存</h4><h5 id="Cached：创建缓存"><a href="#Cached：创建缓存" class="headerlink" title="@Cached：创建缓存"></a>@Cached：创建缓存</h5><pre><code class="java">/**
 * 基于注解创建缓存
 * 缓存在 Remote 的 Redis，也可以配置成 both 开启两级缓存
 */
@Cached(name = CACHE_NAME, key = &quot;#userId&quot;, cacheType = CacheType.LOCAL, expire = 5 * 60)
@CacheRefresh(refresh = 60)
public UserVO findUserById(Long userId) {
    User user = userMapper.selectOne(queryWrapper);
    //.....................
}</code></pre>
<h5 id="CacheInvalidate：删除缓存"><a href="#CacheInvalidate：删除缓存" class="headerlink" title="@CacheInvalidate：删除缓存"></a>@CacheInvalidate：删除缓存</h5><pre><code class="java">@CacheInvalidate(name = CACHE_NAME, key = &quot;#userId&quot;)
@Transactional(rollbackFor = Exception.class)
public int deleteUserById(Long userId) {
    User user = new User();
    user.setId(userId);
    user.setEnable(0);
    UpdateWrapper&lt;User&gt; updateWrapper = new UpdateWrapper&lt;&gt;();
    updateWrapper.lambda().eq(User::getId, userId).eq(User::getEnable, 1);
    return userMapper.update(user, updateWrapper);
}</code></pre>
<h5 id="CacheUpdate：更新缓存"><a href="#CacheUpdate：更新缓存" class="headerlink" title="@CacheUpdate：更新缓存"></a>@CacheUpdate：更新缓存</h5><pre><code class="java">/**
 * 更新用户
 * @param user 用户
 * @return int
 */
@CacheUpdate(name = CACHE_NAME, key = &quot;#user.id&quot;, value = &quot;#user&quot;)
public int updateUser(User user) {
    log.info(&quot;【UserUpdate操作】, user = {}&quot;, JSON.toJSONString(user));
    return userMapper.updateById(user);
}</code></pre>
<h4 id="基于-CreateCache注解创建Cache实例"><a href="#基于-CreateCache注解创建Cache实例" class="headerlink" title="基于@CreateCache注解创建Cache实例"></a>基于@CreateCache注解创建Cache实例</h4><h5 id="CreateCache"><a href="#CreateCache" class="headerlink" title="@CreateCache"></a>@CreateCache</h5><pre><code class="java">/**
 * 使用 @CreateCache 注解创建Cache实例;
 * 未定义默认值的参数，将使用yml中指定的全局配置;
 * 缓存在 Local，也可以配置成 both 开启两级缓存
 */
@CreateCache(name = CACHE_NAME, expire = 5 * 60, localLimit = 10, cacheType = CacheType.LOCAL)
private Cache&lt;Long, UserVO&gt; userCache;</code></pre>
<h5 id="查询缓存"><a href="#查询缓存" class="headerlink" title="查询缓存"></a>查询缓存</h5><pre><code class="java">public UserVO getUserByIdAndCreateCache(Long userId) {
    //根据id从缓存中取
    UserVO userVO = userCache.get(userId);
    log.info(&quot;userCreateCache get {} res {}&quot;, userId, userCache);
    if (Objects.isNull(userVO)) {
        User user = userMapper.selectById(userId);
        if (Objects.nonNull(user)) {
            userVO = new UserVO();
            BeanUtils.copyProperties(user, userVO);
            //如果不存在就放入缓存中
            boolean res = userCache.putIfAbsent(user.getId(), userVO);
            log.info(&quot;userCreateCache putIfAbsent {} res {}&quot;, userId, res);
        }
    }
    return userVO;
}</code></pre>
<h5 id="删除缓存"><a href="#删除缓存" class="headerlink" title="删除缓存"></a>删除缓存</h5><pre><code class="java">@Transactional(rollbackFor = Exception.class)
public int deleteUserByIdAndCreateCache(Long userId) {
    User user = new User();
    UpdateWrapper&lt;User&gt; updateWrapper = new UpdateWrapper&lt;&gt;();
    updateWrapper.lambda().eq(User::getId, userId).eq(User::getEnable, 1);
    user.setId(userId);
    user.setEnable(0);
    int result = userMapper.update(user, updateWrapper);
    if (result &gt; 0) {
        //根据key = userId删除缓存
        boolean deleteResult = userCache.remove(userId);
        log.info(&quot;同步删除缓存, userId = {}, res = {}&quot;, userId, deleteResult);
    }
    return result;
}</code></pre>
]]></content>
      <categories>
        <category>缓存</category>
      </categories>
      <tags>
        <tag>jetcache</tag>
        <tag>缓存</tag>
      </tags>
  </entry>
  <entry>
    <title>Keepalived软件架构</title>
    <url>/2020/08/16/keepalived%E8%BD%AF%E4%BB%B6%E6%9E%B6%E6%9E%84/</url>
    <content><![CDATA[<h3 id="理论介绍"><a href="#理论介绍" class="headerlink" title="理论介绍"></a>理论介绍</h3><h4 id="Keepalived的简介"><a href="#Keepalived的简介" class="headerlink" title="Keepalived的简介"></a>Keepalived的简介</h4><p>​        <code>Keepalived</code>软件起初是专为<code>LVS</code>负载均衡软件设计的，用来管理并监控<code>LVS</code>集群系统中各个服务节点的状态，后来又加入了可以实现高可用的<code>VRRP</code>功能。因此，<code>Keepalived</code>除了能够管理<code>LVS</code>软件外，还可以作为其他服务（例如：<code>Nginx、Haproxy、MySQL</code>等）的高可用解决方案软件。</p>
<p>　　<code>Keepalived</code>软件主要是通过<code>VRRP</code>协议实现高可用功能的。<code>VRRP</code>是<code>Virtual Router RedundancyProtocol</code>(虚拟路由器冗余协议）的缩写，<code>VRRP</code>出现的目的就是为了解决静态路由单点故障问题的，它能够保证当个别节点宕机时，整个网络可以不间断地运行。</p>
<p>​        <strong>所以，<code>Keepalived</code> 一方面具有配置管理<code>LVS</code>的功能，同时还具有对<code>LVS</code>下面节点进行健康检查的功能，另一方面也可实现系统网络服务的高可用功能。</strong></p>
<h4 id="keepalived高可用故障切换转移原理"><a href="#keepalived高可用故障切换转移原理" class="headerlink" title="keepalived高可用故障切换转移原理"></a>keepalived高可用故障切换转移原理</h4><blockquote>
<p>​        <code>Keepalived</code>高可用服务对之间的故障切换转移，是通过<code>VRRP (Virtual Router Redundancy Protocol,虚拟路由器冗余协议）</code>来实现的。</p>
</blockquote>
<p>　　<strong>在 <code>Keepalived</code>服务正常工作时，主 Master节点会不断地向备节点发送（多播的方式）心跳消息，用以告诉备Backup节点自己还活看，当主 Master节点发生故障时，就无法发送心跳消息，备节点也就因此无法继续检测到来自主 Master节点的心跳了，于是调用自身的接管程序，接管主Master节点的 IP资源及服务。而当主 Master节点恢复时，备Backup节点又会释放主节点故障时自身接管的IP资源及服务，恢复到原来的备用角色。</strong></p>
<h4 id="什么是VRRP"><a href="#什么是VRRP" class="headerlink" title="什么是VRRP"></a>什么是VRRP</h4><ol>
<li>VRRP,全称 Virtual Router Redundancy Protocol,中文名为虚拟路由冗余协议，VRRP的出现是为了解决静态路由的单点故障。 </li>
<li>VRRP是通过一种竟选协议机制来将路由任务交给某台 VRRP路由器的。 </li>
<li>VRRP用 IP多播的方式（默认多播地址（224.0_0.18))实现高可用对之间通信。 </li>
<li>工作时主节点发包，备节点接包，当备节点接收不到主节点发的数据包的时候，就启动接管程序接管主节点的开源。备节点可以有多个，通过优先级竞选，但一般 Keepalived系统运维工作中都是一对。 </li>
<li>VRRP使用了加密协议加密数据，但Keepalived官方目前还是推荐用明文的方式配置认证类型和密码。 </li>
</ol>
<hr>
<h4 id="keepalived的工作原理"><a href="#keepalived的工作原理" class="headerlink" title="keepalived的工作原理"></a>keepalived的工作原理</h4><p><img src="http://qiniu.eyestarrysky.top/keepalived%E9%AB%98%E5%8F%AF%E7%94%A8.png" alt=""></p>
<p>​        <strong>Keepalived高可用对之间是通过 VRRP进行通信的， VRRP是遑过竞选机制来确定主备的，主的优先级高于备，因此，工作时主会优先获得所有的资源，备节点处于等待状态，当主挂了的时候，备节点就会接管主节点的资源，然后顶替主节点对外提供服务。</strong></p>
<p>　　<strong>在 Keepalived服务对之间，只有作为主的服务器会一直发送 VRRP广播包,告诉备它还活着，此时备不会枪占主，当主不可用时，即备监听不到主发送的广播包时，就会启动相关服务接管资源，保证业务的连续性.接管速度最快可以小于1秒。</strong></p>
<h3 id="实战演练"><a href="#实战演练" class="headerlink" title="实战演练"></a>实战演练</h3><h4 id="使用Keepalived配置实现虚拟IP在多服务器节点漂移"><a href="#使用Keepalived配置实现虚拟IP在多服务器节点漂移" class="headerlink" title="使用Keepalived配置实现虚拟IP在多服务器节点漂移"></a>使用Keepalived配置实现虚拟IP在多服务器节点漂移</h4><ul>
<li>这里为了节约成本和方便演示，我准备了两台服务器<code>Master 192.168.56.101, Backup 192.168.56.102</code></li>
</ul>
<h5 id="安装keepalived及其配置文件结构"><a href="#安装keepalived及其配置文件结构" class="headerlink" title="安装keepalived及其配置文件结构"></a>安装keepalived及其配置文件结构</h5><pre><code class="shell"># 服务器上安装keepalived
[root@localhost ~]# yum install keepalived -y

# 查看安装目录
[root@localhost ~]# rpm -ql keepalived
/etc/keepalived
/etc/keepalived/keepalived.conf (主配置文件)
/etc/sysconfig/keepalived
/usr/bin/genhash
/usr/lib/systemd/system/keepalived.service
/usr/libexec/keepalived
/usr/sbin/keepalived
/usr/share/doc/keepalived-1.3.5
................

# 查看配置文件
[root@localhost ~]# cat /etc/keepalived/keepalived.conf 
! Configuration File for keepalived

# 全局配置
global_defs {
   # 邮箱地址
   notification_email {
     acassen@firewall.loc
     failover@firewall.loc
     sysadmin@firewall.loc
   }
   notification_email_from Alexandre.Cassen@firewall.loc
   smtp_server 192.168.200.1
   smtp_connect_timeout 30
   # 路由id
   router_id LVS_DEVEL
   vrrp_skip_check_adv_addr
   # 严格的vrrp，建议关掉
#   vrrp_strict
#   vrrp_garp_interval 0
#  vrrp_gna_interval 0
}

# vrrp实例 （名称随意换)
vrrp_instance VI_1 {
    # 说明实例为master节点
    state MASTER
    # 指定的网卡名称
    interface eth0
    virtual_router_id 51
    # 优先值，越大则故障转移时被选中顶替master的几率越大
    priority 100
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    # 虚拟ip地址
    virtual_ipaddress {
        192.168.200.16
        192.168.200.17
        192.168.200.18
    }
}</code></pre>
<h5 id="Master节点配置"><a href="#Master节点配置" class="headerlink" title="Master节点配置"></a>Master节点配置</h5><pre><code class="shell">global_defs {
   notification_email {
     12345678@qq.com
   }
   notification_email_from 188275291160@163.com
   smtp_server 192.168.56.1
   smtp_connect_timeout 30
   router_id Nginx
 # vrrp_skip_check_adv_addr
 # vrrp_strict
 # vrrp_garp_interval 0
 # vrrp_gna_interval 0
}

vrrp_instance Nginx_1 {
    state MASTER
    # 网卡配置 ifconfig查看
    interface enp0s3
    virtual_router_id 51
    priority 100
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    virtual_ipaddress {
        192.168.56.103
    }
}</code></pre>
<h5 id="Backup节点配置"><a href="#Backup节点配置" class="headerlink" title="Backup节点配置"></a>Backup节点配置</h5><pre><code class="shell">! Configuration File for keepalived

global_defs {
   notification_email {
     12345678@qq.com
   }
   notification_email_from 188275291160@163.com
   smtp_server 192.168.56.1
   smtp_connect_timeout 30
   router_id Nginx
 # vrrp_skip_check_adv_addr
 # vrrp_strict
 # vrrp_garp_interval 0
 # vrrp_gna_interval 0
}

# vrrp实例名要与Master一样
vrrp_instance Nginx_1 {
    state BACKUP
    interface enp0s3
  # router_id与master保持一样，说明是同一个vrrp instance
    virtual_router_id 51
  # 优先级比master低  
    priority 98
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    virtual_ipaddress {
        192.168.56.103
    }
}</code></pre>
<h5 id="启动Master-keepalived"><a href="#启动Master-keepalived" class="headerlink" title="启动Master keepalived"></a>启动Master keepalived</h5><pre><code class="shell">[root@localhost keepalived]# systemctl start keepalived
[root@localhost keepalived]# tail -f /var/log/messages
Aug 15 02:57:08 localhost Keepalived[14810]: Starting VRRP child process, pid=14812
Aug 15 02:57:08 localhost Keepalived_healthcheckers[14811]: Opening file &#39;/etc/keepalived/keepalived.conf&#39;.
Aug 15 02:57:08 localhost Keepalived_vrrp[14812]: Registering Kernel netlink reflector
Aug 15 02:57:08 localhost Keepalived_vrrp[14812]: Registering Kernel netlink command channel
Aug 15 02:57:08 localhost Keepalived_vrrp[14812]: Registering gratuitous ARP shared channel
Aug 15 02:57:08 localhost Keepalived_vrrp[14812]: Opening file &#39;/etc/keepalived/keepalived.conf&#39;.
Aug 15 02:57:08 localhost Keepalived_vrrp[14812]: VRRP_Instance(Nginx_1) removing protocol VIPs.
Aug 15 02:57:08 localhost Keepalived_vrrp[14812]: Using LinkWatch kernel netlink reflector...
Aug 15 02:57:08 localhost Keepalived_vrrp[14812]: VRRP sockpool: [ifindex(2), proto(112), unicast(0), fd(10,11)]
Aug 15 02:57:09 localhost Keepalived_vrrp[14812]: VRRP_Instance(Nginx_1) Transition to MASTER STATE
Aug 15 02:57:10 localhost Keepalived_vrrp[14812]: VRRP_Instance(Nginx_1) Entering MASTER STATE
Aug 15 02:57:10 localhost Keepalived_vrrp[14812]: VRRP_Instance(Nginx_1) setting protocol VIPs.
Aug 15 02:57:10 localhost Keepalived_vrrp[14812]: Sending gratuitous ARP on enp0s3 for 192.168.56.103
Aug 15 02:57:10 localhost Keepalived_vrrp[14812]: VRRP_Instance(Nginx_1) Sending/queueing gratuitous ARPs on enp0s3 for 192.168.56.103
Aug 15 02:57:10 localhost Keepalived_vrrp[14812]: Sending gratuitous ARP on enp0s3 for 192.168.56.103
Aug 15 02:57:15 localhost Keepalived_vrrp[14812]: VRRP_Instance(Nginx_1) Sending/queueing gratuitous ARPs on enp0s3 for 192.168.56.103
Aug 15 02:57:15 localhost Keepalived_vrrp[14812]: Sending gratuitous ARP on enp0s3 for 192.168.56.103

# 使用ip a或者ip addr show查看有了192.168.56.103的虚拟ip
[root@localhost keepalived]# ip a
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: enp0s3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:79:dc:34 brd ff:ff:ff:ff:ff:ff
    inet 192.168.56.101/24 brd 192.168.56.255 scope global noprefixroute dynamic enp0s3
       valid_lft 999sec preferred_lft 999sec
    inet 192.168.56.103/32 scope global enp0s3
       valid_lft forever preferred_lft forever
    inet6 fe80::b1d0:38ea:6339:11f8/64 scope link noprefixroute 
       valid_lft forever preferred_lft forever

# ping 发现虚拟ip能够提供服务了
[root@localhost keepalived]# ping 192.168.56.103
PING 192.168.56.103 (192.168.56.103) 56(84) bytes of data.
64 bytes from 192.168.56.103: icmp_seq=1 ttl=64 time=0.082 ms
64 bytes from 192.168.56.103: icmp_seq=2 ttl=64 time=0.035 ms
64 bytes from 192.168.56.103: icmp_seq=3 ttl=64 time=0.036 ms
64 bytes from 192.168.56.103: icmp_seq=4 ttl=64 time=0.037 ms
64 bytes from 192.168.56.103: icmp_seq=5 ttl=64 time=0.072 ms
64 bytes from 192.168.56.103: icmp_seq=6 ttl=64 time=0.036
</code></pre>
<h5 id="启动Backup-keepalived"><a href="#启动Backup-keepalived" class="headerlink" title="启动Backup keepalived"></a>启动Backup keepalived</h5><pre><code class="shell"># VRRP_Instance(Nginx_1) Entering BACKUP STATE
[root@localhost keepalived]# tail -f /var/log/messages
Aug 15 03:03:53 localhost Keepalived_healthcheckers[13529]: Opening file &#39;/etc/keepalived/keepalived.conf&#39;.
Aug 15 03:03:53 localhost Keepalived[13528]: Starting VRRP child process, pid=13530
Aug 15 03:03:53 localhost Keepalived_vrrp[13530]: Registering Kernel netlink reflector
Aug 15 03:03:53 localhost Keepalived_vrrp[13530]: Registering Kernel netlink command channel
Aug 15 03:03:53 localhost Keepalived_vrrp[13530]: Registering gratuitous ARP shared channel
Aug 15 03:03:53 localhost Keepalived_vrrp[13530]: Opening file &#39;/etc/keepalived/keepalived.conf&#39;.
Aug 15 03:03:53 localhost Keepalived_vrrp[13530]: VRRP_Instance(Nginx_1) removing protocol VIPs.
Aug 15 03:03:53 localhost Keepalived_vrrp[13530]: Using LinkWatch kernel netlink reflector...
Aug 15 03:03:53 localhost Keepalived_vrrp[13530]: VRRP_Instance(Nginx_1) Entering BACKUP STATE
Aug 15 03:03:53 localhost Keepalived_vrrp[13530]: VRRP sockpool: [ifindex(2), proto(112), unicast(0), fd(10,11)]

# 当master正常访问时，虚拟ip只会在master上，否则由backup顶上
[root@localhost keepalived]# ip a
1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    inet 127.0.0.1/8 scope host lo
       valid_lft forever preferred_lft forever
    inet6 ::1/128 scope host 
       valid_lft forever preferred_lft forever
2: enp0s3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000
    link/ether 08:00:27:b3:b2:ab brd ff:ff:ff:ff:ff:ff
    inet 192.168.56.102/24 brd 192.168.56.255 scope global noprefixroute dynamic enp0s3
       valid_lft 807sec preferred_lft 807sec
    inet6 fe80::3ddc:9a9a:23b5:44b5/64 scope link noprefixroute 
       valid_lft forever preferred_lft forever

</code></pre>
<h5 id="模拟Master宕机-恢复试验"><a href="#模拟Master宕机-恢复试验" class="headerlink" title="模拟Master宕机-恢复试验"></a>模拟Master宕机-恢复试验</h5><pre><code class="shell"># master重启, 或systemctl stop keepalived模拟宕机
[root@localhost ~]# reboot

# 查看backup日志，发现backup服务器进入MASTER STATE，同时绑定虚拟ip 192.168.56.103
[root@localhost ~]# tail -f /var/log/messages
Aug 15 20:38:09 localhost Keepalived_vrrp[13605]: VRRP_Instance(Nginx_1) Transition to MASTER STATE
Aug 15 20:38:10 localhost Keepalived_vrrp[13605]: VRRP_Instance(Nginx_1) Entering MASTER STATE
Aug 15 20:38:10 localhost Keepalived_vrrp[13605]: VRRP_Instance(Nginx_1) setting protocol VIPs.
Aug 15 20:38:10 localhost Keepalived_vrrp[13605]: Sending gratuitous ARP on enp0s3 for 192.168.56.103
Aug 15 20:38:10 localhost Keepalived_vrrp[13605]: VRRP_Instance(Nginx_1) Sending/queueing gratuitous ARPs on enp0s3 for 192.168.56.103
Aug 15 20:38:10 localhost Keepalived_vrrp[13605]: Sending gratuitous ARP on enp0s3 for 192.168.56.103

# 当原先的MASTER恢复后，查看日志，发现收到广播信息，另一台服务器优先级为100，再次恢复成Backup，同时removing protocols VIPs;
[root@localhost ~]# tail -f /var/log/messages
Aug 15 20:42:37 localhost Keepalived_vrrp[13605]: VRRP_Instance(Nginx_1) Received advert with higher priority 100, ours 98
Aug 15 20:42:37 localhost Keepalived_vrrp[13605]: VRRP_Instance(Nginx_1) Entering BACKUP STATE
Aug 15 20:42:37 localhost Keepalived_vrrp[13605]: VRRP_Instance(Nginx_1) removing protocol VIPs.
</code></pre>
<h4 id="如何修改keepalived日志存放位置"><a href="#如何修改keepalived日志存放位置" class="headerlink" title="如何修改keepalived日志存放位置"></a>如何修改keepalived日志存放位置</h4><pre><code class="shell">[root@localhost ~]# vim /etc/sysconfig/keepalived 
# Options for keepalived. See `keepalived --help&#39; output and keepalived(8) and
# keepalived.conf(5) man pages for a list of all options. Here are the most
# common ones :
#
# --vrrp               -P    Only run with VRRP subsystem.
# --check              -C    Only run with Health-checker subsystem.
# --dont-release-vrrp  -V    Dont remove VRRP VIPs &amp; VROUTEs on daemon stop.
# --dont-release-ipvs  -I    Dont remove IPVS topology on daemon stop.
# --dump-conf          -d    Dump the configuration data.
# --log-detail         -D    Detailed log messages.
# --log-facility       -S    0-7 Set local syslog facility (default=LOG_DAEMON)
#

# 默认的KEEPALIVED_OPTIONS=&quot;-D&quot;
KEEPALIVED_OPTIONS=&quot;-D -d -S 0&quot;

[root@localhost ~]# vim /etc/rsyslog.conf 
# Save boot messages also to boot.log
local7.*                                                /var/log/boot.log
  # 增加这一行配置
local0.*                                             /usr/local/nginx/logs/keepalived.log

[root@localhost ~]# systemctl restart rsyslog
[root@localhost ~]# systemctl restart keepalived</code></pre>
<h4 id="Keepalived-Nginx高可用原理"><a href="#Keepalived-Nginx高可用原理" class="headerlink" title="Keepalived + Nginx高可用原理"></a><code>Keepalived + Nginx</code>高可用原理</h4><ul>
<li>关键点在于，如何使得keepalived知道nginx宕机了。可以写一个脚本监控nginx进程，如果nginx挂了，触发kill掉keepalived，使得VIPs转移到别的服务器，从而实现服务高可用。</li>
</ul>
<pre><code class="shell">[root@localhost shell]# vim nginx_health_check.sh
#!/bin/bash
#

ps -ef | grep nginx | grep -v grep &amp;&gt; /dev/null
# $?不为0（nginx未启动时为0）时杀掉keepalived进程
if [ $? -ne 0]; then
    killall keepalived
fi

# 利用$?（获取上一个命令的退出状态，或者上一个函数的返回值。）, nginx未启动时ps -ef | grep nginx | grep -v grep &amp;&gt; /dev/null 返回1，否则返回0
[root@localhost shell]# ps -ef | grep nginx | grep -v grep &amp;&gt; /dev/null
[root@localhost shell]# echo $?
1</code></pre>
]]></content>
      <categories>
        <category>keepalived</category>
      </categories>
      <tags>
        <tag>keepalived</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式事务解决方案-Seata</title>
    <url>/2021/06/02/%E6%B7%B1%E5%85%A5%E5%89%96%E6%9E%90java%E7%BA%BF%E7%A8%8B%E6%B1%A0/</url>
    <content><![CDATA[<h3 id="一张图概览线程池的处理逻辑"><a href="#一张图概览线程池的处理逻辑" class="headerlink" title="一张图概览线程池的处理逻辑"></a>一张图概览线程池的处理逻辑</h3><p><img src="http://qiniu.eyestarrysky.top/%E7%BA%BF%E7%A8%8B%E6%B1%A0%E5%9B%BE%E7%89%87.png" alt=""></p>
<h3 id="ThreadPoolExecutor的核心参数"><a href="#ThreadPoolExecutor的核心参数" class="headerlink" title="ThreadPoolExecutor的核心参数"></a>ThreadPoolExecutor的核心参数</h3><ul>
<li>先来看看全参构造器</li>
</ul>
<pre><code class="java">public ThreadPoolExecutor(int corePoolSize,
                          int maximumPoolSize,
                          long keepAliveTime,
                          TimeUnit unit,
                          BlockingQueue&lt;Runnable&gt; workQueue,
                          ThreadFactory threadFactory,
                          RejectedExecutionHandler handler) </code></pre>
<h4 id="corePoolSize-核心线程大小"><a href="#corePoolSize-核心线程大小" class="headerlink" title="corePoolSize(核心线程大小)"></a>corePoolSize(核心线程大小)</h4><ul>
<li>当<code>poolSize</code>小于<code>corePoolSize</code>时，线程池会创建一个新的线程来处理任务，即使其它空闲的线程能处理新任务也会创建线程</li>
<li>调用线程池的<code>prestartAllCoreThreads()</code>方法会提前创建，并且启动所有基本线程。</li>
</ul>
<h4 id="maximumPoolSize-线程池的最大数量"><a href="#maximumPoolSize-线程池的最大数量" class="headerlink" title="maximumPoolSize(线程池的最大数量)"></a>maximumPoolSize(线程池的最大数量)</h4><ul>
<li>如果任务队列满了，并且已创建的线程数，小于最大数量，线程池就会创建一个新的线程来处理。</li>
<li>如果<code>workQueue</code>是<font style="color:red;">无界队列</font>，那么这个参数就没效果</li>
</ul>
<h4 id="keepAliveTime-线程存活时间"><a href="#keepAliveTime-线程存活时间" class="headerlink" title="keepAliveTime(线程存活时间)"></a>keepAliveTime(线程存活时间)</h4><ul>
<li>线程的工作线程空闲后保持存活的世界，默认情况下当线程池的线程数小于<code>corePoolSize</code>时生效。当<code>allowCoreThreadTimeOut</code>设置为true时核心线程超时也会被回收</li>
<li>如果任务很多，每个任务执行时间比较短，可以适当调大时间，提高线程利用率</li>
</ul>
<h4 id="workQueue-任务队列"><a href="#workQueue-任务队列" class="headerlink" title="workQueue(任务队列)"></a>workQueue(任务队列)</h4><ul>
<li>用于保存等待执行的任务的阻塞队列。可以选择以下几个阻塞队列。<ul>
<li><code>ArrayBlockingQueue</code>：是一个基于数组结构的有界阻塞队列，此队列按FIFO（先进先出）原则对元素进行排序。</li>
<li><code>LinkedBlockingQueue</code>：一个基于链表结构的阻塞队列，此队列按FIFO排序元素，吞吐量通常要高于<code>ArrayBlockingQueue</code>。静态工厂方法<code>Executors.newFixedThreadPool()</code>使用了这个队列。</li>
<li><code>SynchronousQueue</code>：一个不存储元素的阻塞队列。每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于<code>LinkedBlockingQueue</code>，静态工厂方法<code>Executors.newCachedThreadPool</code>使用了这个队列。</li>
<li><code>priorityBlockingQueue</code>：一个具有优先级的无限阻塞队列。</li>
</ul>
</li>
</ul>
<h4 id="threadFactory-线程工厂"><a href="#threadFactory-线程工厂" class="headerlink" title="threadFactory(线程工厂)"></a>threadFactory(线程工厂)</h4><ul>
<li><p>用于设置创建线程的工厂，可以通过线程工厂给每个创建出来的线程设置更有意义的名字。</p>
</li>
<li><p>使用开源框架guava提供的<code>ThreadFactoryBuilder</code>可以快速给线程池里的线程设置有意义的名字，代码如下。</p>
<pre><code class="java">new ThreadFactoryBuilder().setNameFormat(&quot;XX-task-%d&quot;).build();</code></pre>
</li>
</ul>
<h4 id="handler-饱和策略"><a href="#handler-饱和策略" class="headerlink" title="handler(饱和策略)"></a>handler(饱和策略)</h4><p>当队列和线程池都满了，说明线程池处于饱和状态，那么必须采取一种策略处理提交的新任务。这个策略默认情况下是<code>AbortPolicy</code>，表示无法处理新任务时抛出异常。在JDK 1.5中Java线程池框架提供了以下4种策略。</p>
<ul>
<li><code>AbortPolicy</code>：直接抛出异常。</li>
<li><code>CallerRunsPolicy</code>：调用任务的<code>run()</code>方法绕过线程池直接执行。</li>
<li><code>DiscardOldestPolicy</code>：丢弃队列里最近节点的一个任务，并执行当前任务。</li>
<li><code>DiscardPolicy</code>：不处理，丢弃掉。</li>
</ul>
<h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><ol>
<li>如果当前运行的线程少于<code>corePoolSize</code>，则创建新线程来执行任务（注意，执行这一步骤需要获取全局锁）。</li>
<li>如果运行的线程等于或多于<code>corePoolSize</code>，则将任务加入<code>BlockingQueue</code>。</li>
<li>如果无法将任务加入<code>BlockingQueue</code>（队列已满），则创建新的线程来处理任务（注意，执行这一步骤需要获取全局锁）。</li>
<li>如果创建新线程将使当前运行的线程超出<code>maximumPoolSize</code>，任务将被拒绝，并调用<code>RejectedExecutionHandler.rejectedExecution()</code>方法。根据不同的拒绝策略去处理。</li>
</ol>
<p><strong>ThreadPoolExecutor采取上述步骤的总体设计思路，是为了在执行execute()方法时，尽可能地避免获取全局锁（那将会是一个严重的可伸缩瓶颈）。在ThreadPoolExecutor完成预热之后（当前运行的线程数大于等于corePoolSize），几乎所有的execute()方法调用都是执行步骤2，而步骤2不需要获取全局锁。</strong></p>
<h3 id="核心源码剖析"><a href="#核心源码剖析" class="headerlink" title="核心源码剖析"></a>核心源码剖析</h3><h4 id="处理线程池状态和工作队列的参数-ctl"><a href="#处理线程池状态和工作队列的参数-ctl" class="headerlink" title="处理线程池状态和工作队列的参数 - ctl"></a>处理线程池状态和工作队列的参数 - ctl</h4><pre><code class="java">private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));
   // 29
   private static final int COUNT_BITS = Integer.SIZE - 3; 
   // 000-1(29个1)
   private static final int CAPACITY  = (1 &lt;&lt; COUNT_BITS) - 1;

   //用左边3位，实现5种线程状态
   //111-0,,,  此状态表示线程池能接收新的任务，十进制为: -536,870,912
   private static final int RUNNING    = -1 &lt;&lt; COUNT_BITS;

   //000-0...  此此状态不接受新的任务，但是可以继续执行队列中的任务
   private static final int SHUTDOWN   =  0 &lt;&lt; COUNT_BITS;

   //001-0...  此状态全面拒绝，并中断正在处理的任务 十进制为: 536,870,912
   private static final int STOP       =  1 &lt;&lt; COUNT_BITS;

   //010-0...  此状态表示所有任务已经被终止
   private static final int TIDYING    =  2 &lt;&lt; COUNT_BITS;

   //011-0...  此状态表示已经清理完现场
   private static final int TERMINATED =  3 &lt;&lt; COUNT_BITS;

   // ~掩码取反
   private static int runStateOf(int c)     { return c &amp; ~CAPACITY; }
   // 获取工作线程数目
   private static int workerCountOf(int c)  { return c &amp; CAPACITY; }
   // 合并rs(工作状态)和wc(工作线程数) 或运算 到一个32位数中
   private static int ctlOf(int rs, int wc) { return rs | wc; }</code></pre>
<h4 id="线程池状态及状态切换"><a href="#线程池状态及状态切换" class="headerlink" title="线程池状态及状态切换"></a>线程池状态及状态切换</h4><ul>
<li><code>RUNNING</code>：能接受新任务，并处理阻塞队列中的任务</li>
<li><code>SHUTDOWN</code>：不接受新任务，但是可以处理阻塞队列中的任务</li>
<li><code>STOP</code>：不接受新任务，并且不处理阻塞队列中的任务，并且还打断正在运行任务的线程，就是直接撂担子不干了！</li>
<li><code>TIDYING</code>：所有任务都终止，并且工作线程也为0，处于关闭之前的状态</li>
<li><code>TERMINATED</code>：已关闭。</li>
</ul>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/eSdk75TK4nFApmmGxuSmkFnGZIczU6HYs2XzibU6JNtBALibRhZTFWPVicaQ5IYst97Zh1mOIlSdJLbanMEIX8N4w/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" alt=""></p>
<h4 id="execute方法"><a href="#execute方法" class="headerlink" title="execute方法"></a>execute方法</h4><pre><code class="java">public void execute(Runnable command) {
    //如果提交了空的任务 抛出异常
    if (command == null)
        throw new NullPointerException();
    int c = ctl.get();//获取当前线程池的状态
    //检查当前工作线程数量是否小于核心线程数量
    if (workerCountOf(c) &lt; corePoolSize) {
        // 通过addWorker方法提交任务
        if (addWorker(command, true))
            return;
        c = ctl.get();//如果提交失败 需要二次检查状态
    }
    //向工作线程提交任务，如果线程池为running，则将线程加入等待队列
    if (isRunning(c) &amp;&amp; workQueue.offer(command)) {
        // 再次检查状态
        int recheck = ctl.get();
        //如果重新检查发现线程池不为ruuning，就从队列中移除线程，并执行拒绝策略
        if (!isRunning(recheck) &amp;&amp; remove(command))
            reject(command);
        //如果之前的线程已经消费完，就新建一个线程
        else if (workerCountOf(recheck) == 0)
            addWorker(null, false);
    }
    //如果核心池和等待队列都满了，则尝试创建一个新线程
    else if (!addWorker(command, false))
        //如果addWork()返回false，则执行拒绝策略
        reject(command);
}</code></pre>
<h4 id="Worker类"><a href="#Worker类" class="headerlink" title="Worker类"></a>Worker类</h4><ul>
<li><code>Worker</code></li>
</ul>
<pre><code class="java">private final class Worker
        extends AbstractQueuedSynchronizer
        implements Runnable
    {

        /** Thread this worker is running in.  Null if factory fails. */
        final Thread thread;
        /** Initial task to run.  Possibly null. */
        Runnable firstTask;
        /** Per-thread task counter */
        volatile long completedTasks;

        /**
         * 这里传入任务，并将Worker自己放入到thread中
         */
        Worker(Runnable firstTask) {
            setState(-1); // inhibit interrupts until runWorker
            this.firstTask = firstTask;
            //
            this.thread = getThreadFactory().newThread(this);
        }

        /** 后续工作线程执行的时候触发这里  */
        public void run() {
            runWorker(this);
        }
    }</code></pre>
<h4 id="addWorker方法"><a href="#addWorker方法" class="headerlink" title="addWorker方法"></a>addWorker方法</h4><ul>
<li>这个方法是任务提交的一个核心方法。在里面完成了状态检查、新建任务、执行任务等一系列动作。</li>
</ul>
<pre><code class="java">/**
 * 检查是否能添加一个新的任务线程，如果可以则创建并启动任务
 * 返回false的可能性如下：
 * 1.线程池不为RUNNING状态
 * 2.线程工厂创建新的任务线程失败
 * firstTask: 外部启动线程池时需要构造的第一个线程
 */
private boolean addWorker(Runnable firstTask, boolean core) {
    //循环标记
       retry:
   //死循环更新状态
       for (;;) {
           int c = ctl.get();
           int rs = runStateOf(c);//获取运行状态

       //检查线程池是否处于关闭状态
           if (rs &gt;= SHUTDOWN &amp;&amp;
               ! (rs == SHUTDOWN &amp;&amp;
                  firstTask == null &amp;&amp;
                  ! workQueue.isEmpty()))
               return false;

           for (;;) {
         // 获取当前工作线程数量
               int wc = workerCountOf(c);
       //如果已经超过corePoolSize获取maximumPoolSize 返回false
               if (wc &gt;= CAPACITY ||
                   wc &gt;= (core ? corePoolSize : maximumPoolSize))
                   return false;
       //CAS增加一个工作线程
               if (compareAndIncrementWorkerCount(c))
                break retry;
       //再次获取状态
               c = ctl.get();  // Re-read ctl
       //如果状态更新失败 则循环更新
               if (runStateOf(c) != rs)
                   continue retry;
               // else CAS failed due to workerCount change; retry inner loop
           }
       }

       boolean workerStarted = false;
       boolean workerAdded = false;
       Worker w = null;
       try {
           w = new Worker(firstTask);//初始化一个工作线程
           final Thread t = w.thread;
           if (t != null) {
               // 获得全局锁
               final ReentrantLock mainLock = this.mainLock;
               mainLock.lock();
               try {
                   // Recheck while holding lock.
                   // Back out on ThreadFactory failure or if
                   // shut down before lock acquired.
                   int rs = runStateOf(ctl.get());

                   if (rs &lt; SHUTDOWN ||
                       (rs == SHUTDOWN &amp;&amp; firstTask == null)) {
                       if (t.isAlive()) // precheck that t is startable
                           throw new IllegalThreadStateException();
                          // 添加工作到hashset中保存
                       workers.add(w);
                       int s = workers.size();
                       if (s &gt; largestPoolSize)
                           largestPoolSize = s;
                       workerAdded = true;
                   }
               } finally {
                   mainLock.unlock();
               }
               if (workerAdded) {
                      // 工作线程启动 执行第一个任务 就是新提交的任务
                   t.start();
                   workerStarted = true;
               }
           }
       } finally {
           if (! workerStarted)
               addWorkerFailed(w);
       }
       return workerStarted;
   }</code></pre>
<h4 id="runWorker方法"><a href="#runWorker方法" class="headerlink" title="runWorker方法"></a>runWorker方法</h4><ul>
<li><p>在看<code>addWorker</code>时发现，当工作线程创建成功后，会调用<code>t.start()</code>我们知道它实际执行的就是<code>Worker</code>对象的<code>run()</code>方法，而<code>worker</code>的<code>run()</code>方法是这样定义的：</p>
<pre><code class="java">public void run() {
    runWorker(this);
}</code></pre>
</li>
<li><p>它实际上是将自己委托给线程池的<code>runWorker</code>方法，不断执行我们提交的任务的run方法。而这个任务可能是我们新提交的，也有可能是从等待队列中获取的。这样就实现了线程池的完成逻辑。</p>
<pre><code class="java">final void runWorker(Worker w) {
    Thread wt = Thread.currentThread();
    Runnable task = w.firstTask;
    w.firstTask = null;
    w.unlock(); // allow interrupts
    boolean completedAbruptly = true;
       try {
       //不断地从blockingQueue获取任务
           while (task != null || (task = getTask()) != null) {
               w.lock();
               // If pool is stopping, ensure thread is interrupted;
               // if not, ensure thread is not interrupted.  This
               // requires a recheck in second case to deal with
               // shutdownNow race while clearing interrupt
               if ((runStateAtLeast(ctl.get(), STOP) ||
                    (Thread.interrupted() &amp;&amp;
                     runStateAtLeast(ctl.get(), STOP))) &amp;&amp;
                   !wt.isInterrupted())
                   wt.interrupt();
               try {
           //执行beforeExecute方法
                   beforeExecute(wt, task);
                   Throwable thrown = null;
                   try {
           //调用Runable的run方法
                       task.run();
                   } catch (RuntimeException x) {
                       thrown = x; throw x;
                   } catch (Error x) {
                       thrown = x; throw x;
                   } catch (Throwable x) {
                       thrown = x; throw new Error(x);
                   } finally {
                          // 执行aferExecute方法
                       afterExecute(task, thrown);
                   }
               } finally {
                   task = null;
                   w.completedTasks++;
                   w.unlock();
               }
           }
           completedAbruptly = false;
       } finally {
           processWorkerExit(w, completedAbruptly);
       }
}</code></pre>
</li>
</ul>
<h3 id="自己动手实现一个简易线程池"><a href="#自己动手实现一个简易线程池" class="headerlink" title="自己动手实现一个简易线程池"></a>自己动手实现一个简易线程池</h3><h4 id="线程池类"><a href="#线程池类" class="headerlink" title="线程池类"></a>线程池类</h4><pre><code class="java">@Slf4j
public class SimpleThreadPoolExecutor {

    private final BlockingQueue&lt;Runnable&gt; blockingQueue;

    public SimpleThreadPoolExecutor(BlockingQueue&lt;Runnable&gt; blockingQueue, int threadSize) {
        this.blockingQueue = blockingQueue;
        Set&lt;SimpleThread&gt; workThreads = new HashSet&lt;&gt;();
        for (int i = 0; i &lt; threadSize; i++) {
            SimpleThread simpleThread = new SimpleThread(&quot;simpleThread-&quot; + i);
            simpleThread.start();
            workThreads.add(simpleThread);
        }
    }

    public void execute(Runnable task) {
        blockingQueue.add(task);
    }

    @Data
    private final class SimpleThread extends Thread {

        public SimpleThread(@NotNull String name) {
            super(name);
        }

        @Override
        public void run() {
            while (true) {
                try {
                    // 这里如果没有任务，会一直阻塞(底层调了LockSupport.park(this))
                    Runnable task = blockingQueue.take();
                    task.run();
                } catch (InterruptedException e) {
                    e.printStackTrace();
                    log.error(&quot;【获取任务发生异常】, 错误信息 = {}&quot;, ExceptionUtils.getRootCauseMessage(e));
                }
            }
        }
    }

}</code></pre>
<h4 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h4><pre><code class="java">public static void main(String[] args) {
    SimpleThreadPoolExecutor executor =
        new SimpleThreadPoolExecutor(new LinkedBlockingQueue&lt;&gt;(), Runtime.getRuntime().availableProcessors());
    Random r = new Random();
    for (int i = 0; i &lt; 100; i++) {
        executor.execute(() -&gt; System.err.println(Thread.currentThread().getName() + &quot;: 执行结果为&quot; + r.nextInt(100)));
    }
}

-------------  测试结果
simpleThread-0: 执行结果为51
simpleThread-1: 执行结果为55
simpleThread-4: 执行结果为74
simpleThread-7: 执行结果为21
simpleThread-4: 执行结果为36
simpleThread-1: 执行结果为57
simpleThread-6: 执行结果为81
......</code></pre>
<h3 id="几道关于线程池的问题及解答"><a href="#几道关于线程池的问题及解答" class="headerlink" title="几道关于线程池的问题及解答"></a>几道关于线程池的问题及解答</h3><h4 id="问题一"><a href="#问题一" class="headerlink" title="问题一"></a>问题一</h4><blockquote>
<p>如果线程数小于核心线程数，并且线程都处于空闲状态，现提交一个任务，是新起一个线程还是给之前创建的线程？ </p>
</blockquote>
<ul>
<li>线程池会新起一个线程来执行这个新任务，不管老线程是否空闲。 </li>
</ul>
<h4 id="问题二"><a href="#问题二" class="headerlink" title="问题二"></a>问题二</h4><blockquote>
<p>如果线程池中的线程在执行任务的时候，抛异常了，会怎么样？</p>
</blockquote>
<ul>
<li>查看<code>runWorker</code>方法，如果发生异常会进入到<code>afterExecute(task, thrown)</code>， 并且也继续被抛了出来 ，进入<code>processWorkerExit(w, completedAbruptly)</code>方法</li>
<li>简而言之把<strong><font style="color:red;">这个线程废了，然后新建一个线程。 </font></strong></li>
</ul>
<pre><code class="java">    private void processWorkerExit(Worker w, boolean completedAbruptly) {
        if (completedAbruptly) // If abrupt, then workerCount wasn&#39;t adjusted
            decrementWorkerCount();

        final ReentrantLock mainLock = this.mainLock;
        mainLock.lock();
        try {
            completedTaskCount += w.completedTasks;
            // 移除了线程的引用, gc会处理
            workers.remove(w);
        } finally {
            mainLock.unlock();
        }

        tryTerminate();

        int c = ctl.get();
        if (runStateLessThan(c, STOP)) {
            if (!completedAbruptly) {
                int min = allowCoreThreadTimeOut ? 0 : corePoolSize;
                if (min == 0 &amp;&amp; ! workQueue.isEmpty())
                    min = 1;
                if (workerCountOf(c) &gt;= min)
                    return; // replacement not needed
            }
            // 新加入一个线程
            addWorker(null, false);
        }
    }</code></pre>
<h4 id="问题三"><a href="#问题三" class="headerlink" title="问题三"></a>问题三</h4><blockquote>
<p>线程池的核心线程在空闲的时候一定不会被回收吗？ </p>
</blockquote>
<ul>
<li>有个 <code>allowCoreThreadTimeOut</code> 方法，把它设置为 true ，则所有线程都会超时时间，不会有核心数那条线的存在。具体是会调用 <code>interruptIdleWorkers</code> 这个方法</li>
</ul>
<h4 id="问题四"><a href="#问题四" class="headerlink" title="问题四"></a>问题四</h4><blockquote>
<p>线程池如何动态修改核心线程数和最大线程数？ </p>
</blockquote>
<p>其实之所以会有这样的需求是因为线程数是真的不好配置。</p>
<p>你可能会在网上或者书上看到很多配置公式，比如：</p>
<ul>
<li><strong>CPU 密集型的话，核心线程数设置为 CPU核数+1</strong></li>
<li><strong>I/O 密集型的话，核心线程数设置为 2 * CPU核数</strong></li>
</ul>
<p>比如：<strong>线程数=CPU核数 *（1+线程等待时间 / 线程时间运行时间）</strong></p>
<p>这个比上面的更贴合与业务，还有一些理想的公式就不列了。就这个公式而言，这个线程等待时间就很难测，拿 Tomcat 线程池为例，每个请求的等待时间能知道？不同的请求不同的业务，就算相同的业务，不同的用户数据量也不同，等待时间也不同。</p>
<p>所以说线程数真的很难通过一个公式一劳永逸，线程数的设定是一个迭代的过程，需要压测适时调整，以上的公式做个初始值开始调试是 ok 的。</p>
<p>再者，流量的突发性也是无法判断的，举个例子 1 秒内一共有 1000 个请求量，但是如果这 1000 个请求量都是在第一毫秒内瞬时进来的呢？</p>
]]></content>
      <categories>
        <category>java</category>
        <category>线程池</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title>利用github和hexo快速搭建个人博客</title>
    <url>/2020/04/17/%E5%88%A9%E7%94%A8github%E5%92%8Chexo%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/</url>
    <content><![CDATA[<h3 id="一、准备工作"><a href="#一、准备工作" class="headerlink" title="一、准备工作"></a>一、准备工作</h3><h4 id="安装git"><a href="#安装git" class="headerlink" title="安装git"></a>安装git</h4><p><code>git</code>下载地址：<code>http://gitforwindows.org</code></p>
<h4 id="安装node-js"><a href="#安装node-js" class="headerlink" title="安装node.js"></a>安装node.js</h4><p> <code>node.js</code> 下载地址：<code>http://nodejs.org/en/</code> </p>
<h3 id="二、本地搭建"><a href="#二、本地搭建" class="headerlink" title="二、本地搭建"></a>二、本地搭建</h3><ul>
<li><p>选择一个文件夹建一个目录<code>blog</code>存放博客相关文件，文件夹内右键打开<code>git bash here</code>，在窗口中执行以下所有命令</p>
</li>
<li><p>用<code>npm</code>安装<code>hexo</code>，由于国内网络高“墙”深院，避免安装缓慢或失败，这里切换阿里的<code>NPM</code>镜像，没办法只能采用迂回战术了。</p>
</li>
</ul>
<pre><code class="sh">$ npm install -g cnpm --registry=http://registry.npm.taobao.org</code></pre>
<p>用 <code>cnpm</code> 安装 <code>hexo</code></p>
<pre><code class="sh">$ cnpm install -g hexo-cli
$ cnpm install hexo --save
##检查hexo是否安装成功
$ hexo -v</code></pre>
<ul>
<li>在<code>blog</code>文件夹建一个<code>hexo</code>文件存放博客，进入也打开<code>git bash here</code></li>
</ul>
<pre><code class="sh">$ hexo init</code></pre>
<p>初始化成功后，<code>hexo文件</code>夹内会出现如下的文件：</p>
<p><code>node_modules</code>: 依赖包<br><code>public</code>：存放生成的页面<br><code>scaffolds</code>：生成文章的一些模板<br><code>source</code>：用来存放你的文章<br><code>themes</code>：放下下载的主题<br><code>_config.yml:</code> 博客的核心配置文件（设置主体、标题等属性）</p>
<ul>
<li><p>接着需要执行一下<code>cnpm install</code>命令，要不下边的启动会提示命令不合法。</p>
</li>
<li><p>最后使用<code>hexo s -g</code>启动安装好的<code>hexo</code></p>
</li>
</ul>
<h3 id="三、托管至GitHub"><a href="#三、托管至GitHub" class="headerlink" title="三、托管至GitHub"></a>三、托管至GitHub</h3><ul>
<li><p>建立一个仓库，名称为<code>xxx.github.io</code></p>
</li>
<li><p>配置<code>_config.xml</code>文件，添加<code>GitHub</code>地址</p>
</li>
</ul>
<pre><code class="yml">deploy:
  type: git
  repo: https://github.com/xxx/xxx.github.io.git
  branch: master</code></pre>
<ul>
<li>安装部署命令<code>deploy-git</code> ，这样你才能用命令部署到<code>GitHub</code></li>
</ul>
<pre><code class="sh">$ cnpm install hexo-deployer-git  --save</code></pre>
<ul>
<li>安装好后，依次执行下列命令，提交本地<code>hexo</code>文件到<code>GitHub</code></li>
</ul>
<pre><code class="sh">$ hexo clean
$ hexo generate
$ hexo deploy</code></pre>
<ul>
<li>最后访问<code>https://xxx.github.io.git</code>即可</li>
</ul>
<h3 id="四、选择自己喜欢的主题"><a href="#四、选择自己喜欢的主题" class="headerlink" title="四、选择自己喜欢的主题"></a>四、选择自己喜欢的主题</h3><ul>
<li><p>到<code>http://hexo.io/themes/</code>下载主题，<code>git clone</code>到本地</p>
<p><code>git clone https://github.com/iissnan/hexo-theme-next</code></p>
</li>
<li><p>修改<code>hexo</code>文件夹下的<code>_config.yml</code>文件中的<code>theme</code>属性</p>
</li>
</ul>
<pre><code class="yml">theme: hexo-theme-next</code></pre>
<ul>
<li>再次打包上传即可<pre><code class="sh">$ hexo clean
$ hexo generate
$ hexo deploy</code></pre>
</li>
</ul>
<h3 id="五、Hexo基本操作"><a href="#五、Hexo基本操作" class="headerlink" title="五、Hexo基本操作"></a>五、Hexo基本操作</h3><p>博客文章都放在<code>source\_post</code>目录下</p>
]]></content>
      <categories>
        <category>hexo</category>
        <category>建站</category>
      </categories>
      <tags>
        <tag>建站</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式协议与算法-Raft算法</title>
    <url>/2020/09/05/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%AE%AE%E4%B8%8E%E7%AE%97%E6%B3%95-Raft%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><blockquote>
<p>为了对分布式系统有更深的理解，也为了我的技术成长提供更多可能性，我花了部分时间对目前分布式系统设计中比较常用或者重要的算法进行了学习，最终整理出这篇文章。以前学习时，对于分布式，高可用，集群，leader选举等一系列核心问题都是一知半解，希望日后我也能时常勉励自己，有时间可以再回过头来看看这篇博客，做到见微知著，举一反三。</p>
</blockquote>
<h3 id="Paxos算法简介"><a href="#Paxos算法简介" class="headerlink" title="Paxos算法简介"></a>Paxos算法简介</h3><ul>
<li><p>我看了很多文章，对于<code>Paxos</code>算法还是一知半解，所以这里只是对<code>Paxos</code>算法做简单的总结。</p>
</li>
<li><p><code>Paxos</code>算法包含两个重要部分</p>
<ol>
<li><code>Basic-Paxos</code>算法，描述的是多节点之间如何就某个提案达成共识</li>
<li><code>Muti-Paxos</code>算法，描述的是执行多个<code>Basic-Paxos</code>实例，就一系列提案达成共识。下面要说的的<code>Raft</code>算法就是基于<code>Multi-Paxos</code>思想的共识算法之一。</li>
</ol>
</li>
</ul>
<h3 id="Raft算法"><a href="#Raft算法" class="headerlink" title="Raft算法"></a>Raft算法</h3><ul>
<li><code>Raft</code>算法是现在分布式系统开发首选的共识算法。</li>
<li><code>Raft</code>算法是强领导者模型，集群中只能有一个<code>Leader</code></li>
</ul>
<h4 id="成员身份"><a href="#成员身份" class="headerlink" title="成员身份"></a>成员身份</h4><ol>
<li><code>Follower</code>：接收和处理来自<code>Leader</code>的消息，跟<code>Leader</code>心跳超时时，就变为<code>Candidate</code></li>
<li><code>Candidate</code>：候选人向其他节点发送<code>RPC</code>消息请求投票，通知它们投票，如果赢得了大多数选票就晋升为<code>Leader</code></li>
<li><code>Leader</code>：处理写请求，管理日志复制和不断发送心跳消息，通知其他节点。</li>
</ol>
<h4 id="Leader选举"><a href="#Leader选举" class="headerlink" title="Leader选举"></a>Leader选举</h4><ul>
<li>初始状态时，集群中所有的节点都是跟随者的状态。<code>Raft</code>实现了随机超时时间的特性，每个节点等待领导者节点心跳信息的超时时间间隔是随机的。可以看到，下图中节点A会最先因为没有收到<code>leader</code>心跳信息发生超时。这个时候节点A就会增加自己的任期编号，并且推举自己为<code>Candidate</code>，并给自己投上一票，然后向其他节点发送<code>RPC</code>请求投票。</li>
</ul>
<p><img src="http://qiniu.eyestarrysky.top/Raft%E7%AE%97%E6%B3%95-Leader%E9%80%89%E4%B8%BE1.png" alt=""></p>
<ul>
<li><p>其他节点收到候选者A的投票请求，在编号为1的这届任期没有进行过投票，那么它将把选票投给A，并增加自己的任期编号。</p>
</li>
<li><p>如果候选人A在选举超时时间内赢得了大多数的选票，那么它就会成为本届任期内新的<code>Leader</code></p>
</li>
<li><p>节点A当选<code>Leader</code>后，他将周期性地发送心跳消息，通知其他服务器我是领导者，阻止跟随者发起新的选举</p>
</li>
</ul>
<h4 id="日志复制"><a href="#日志复制" class="headerlink" title="日志复制"></a>日志复制</h4><h5 id="日志的基本介绍"><a href="#日志的基本介绍" class="headerlink" title="日志的基本介绍"></a>日志的基本介绍</h5><blockquote>
<p>在 Raft 算法中，副本数据是以日志的形式存在的，领导者接收到来自客户端写请求后，处理写请求的过程就是一个复制和提交日志项的过程。</p>
</blockquote>
<ul>
<li><h5 id="日志由日志项组成。而日志项主要包含用户指定的数据，也就是指令（Command），还包含一些附加信息，比如索引值（Log-index）、任期编号（Term）。"><a href="#日志由日志项组成。而日志项主要包含用户指定的数据，也就是指令（Command），还包含一些附加信息，比如索引值（Log-index）、任期编号（Term）。" class="headerlink" title="日志由日志项组成。而日志项主要包含用户指定的数据，也就是指令（Command），还包含一些附加信息，比如索引值（Log index）、任期编号（Term）。"></a>日志由日志项组成。而日志项主要包含用户指定的数据，也就是指令（Command），还包含一些附加信息，比如索引值（Log index）、任期编号（Term）。</h5></li>
</ul>
<p><img src="http://qiniu.eyestarrysky.top/Raft%E6%97%A5%E5%BF%97%E9%A1%B9.png" alt=""></p>
<ul>
<li>需要注意的是，<strong><font style="color:red">一届Leader任期内，往往有多条日志项，而且日志项的索引值是连续的。</font></strong></li>
</ul>
<h5 id="日志复制的过程"><a href="#日志复制的过程" class="headerlink" title="日志复制的过程"></a>日志复制的过程</h5><ul>
<li><p>首先，领导者进入第一阶段，通过日志复制(AppendEntries) RPC 消息，将日志项复制到集群其他节点上。接着，如果领导者接收到大多数的”复制成功”响应后，它将日志项提交到它的状态机，并返回成功给客户端。如果领导者没有接收到大多数的”复制成功”响应，那么就返回错误给客户端。</p>
</li>
<li><p>具体而言会分为以下几步：</p>
<ol>
<li><code>Leader</code>基于客户端请求的指令，创建一个新的日志项，并附加到本地日志中。</li>
<li><code>Leader</code>通过日志复制<code>RPC</code>操作，将新的日志项复制到其他服务器。</li>
<li>当<code>Leader</code>将日志项，成功复制到大多数服务器上的时候，<code>Leader</code>会将这条日志项提交到它的状态机中。</li>
<li><code>Leader</code>将执行的结果返回给客户端。</li>
<li>当<code>Leader</code>接收到心跳信息，或者新的日志复制<code>RPC</code>消息后，如果<code>Followers</code>发现<code>Leader</code>已经提交了某条日志项，而它还没提交，那么它就将这条日志项提交到本机的状态机中。</li>
</ol>
</li>
</ul>
<h4 id="成员变更"><a href="#成员变更" class="headerlink" title="成员变更"></a>成员变更</h4><p>​        日常工作中服务器故障的情况偶尔也会出现，这时就要替换故障的服务器。如果遇到需要改变数据副本（服务器）数的情况，则需要增加或移除集群中的服务器，总的来说，在生产环境中集群的服务器数量是会发生变化的。</p>
<ul>
<li>集群的配置：集群中各节点地址的集合。比如节点A、B、C组成的集群，那么集群的配置就是[A、B、C]集合。</li>
</ul>
<h5 id="成员变更的带来的问题"><a href="#成员变更的带来的问题" class="headerlink" title="成员变更的带来的问题"></a>成员变更的带来的问题</h5><ul>
<li>在集群中进行成员变更的最大风险是，可能会同时出现 2 个领导者。比如在进行成员变更时，节点 A、B 和 C 之间发生了分区错误，节点 A、B 组成旧配置中的“大多数”，也就是变更前的 3 节点集群中的“大多数”，那么这时的领导者（节点 A）依旧是领导者。  另一方面，节点 C 和新节点 D、E 组成了新配置的“大多数”，也就是变更后的 5 节点集群中的“大多数”，它们可能会选举出新的领导者（比如节点 C）。那么这时，就出现了同时存在 2 个领导者的情况。 </li>
</ul>
<p><img src="http://qiniu.eyestarrysky.top/%E6%88%90%E5%91%98%E5%8F%98%E6%9B%B4%E5%A4%9Aleader.png" alt=""></p>
<h5 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h5><ul>
<li>通过单节点变更解决成员变更出现的极端情况。顾名思义，单节点变更就是通过一次变更一个节点实现成员变更。如果需要变更多个节点，就就行多次单节点变更。</li>
</ul>
<h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><blockquote>
<p>Raft 不是一致性算法而是共识算法，是一个 Multi-Paxos 算法，实现的是如何就一系列值达成共识。并且，Raft 能容忍少数节点的故障。虽然 Raft 算法能实现强一致性，也就是线性一致性（Linearizability），但需要客户端协议的配合。在实际场景中，我们一般需要根据场景特点，在一致性强度和实现复杂度之间进行权衡。比如 Consul 实现了三种一致性模型。</p>
</blockquote>
<ul>
<li><p><code>default</code>：客户端访问领导者节点执行读操作，领导者确认自己处于稳定状态时（在 leader leasing 时间内），返回本地数据给客户端，否则返回错误给客户端。在这种情况下，客户端是可能读到旧数据的，比如此时发生了网络分区错误，新领导者已经更新过数据，但因为网络故障，旧领导者未更新数据也未退位，仍处于稳定状态。 </p>
</li>
<li><p><code>consistent</code>：客户端访问领导者节点执行读操作，领导者在和大多数节点确认自己仍是领导者之后返回本地数据给客户端，否则返回错误给客户端。在这种情况下，客户端读到的都是最新数据。 </p>
</li>
<li><p><code>stale</code>：从任意节点读数据，不局限于领导者节点，客户端可能会读到旧数据。 </p>
<p><strong>一般而言，在实际工程中，Consul 的 consistent 就够用了，可以不用线性一致性，只要能保证写操作完成后，每次读都能读到最新值就可以了。比如为了实现冥等操作，我们使用一个编号 (ID) 来唯一标记一个操作，并使用一个状态字段（nil/done）来标记操作是否已经执行，那么只要我们能保证设置了 ID 对应状态值为 done 后，能立即和一直读到最新状态值就可以了，也就通过防止操作的重复执行，实现了冥等性。</strong> </p>
</li>
</ul>
<p>​      *<em>总的来说，Raft 算法能很好地处理绝大部分场景的一致性问题，在设计分布式系统时，优先考虑 Raft 算法，当 Raft 算法不能满足现有场景需求时，再去调研其他共识算法。 *</em></p>
]]></content>
      <categories>
        <category>分布式</category>
      </categories>
      <tags>
        <tag>分布式</tag>
      </tags>
  </entry>
  <entry>
    <title>分布式事务解决方案-Seata</title>
    <url>/2021/05/26/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88-Seata/</url>
    <content><![CDATA[<h3 id="写在前面的话"><a href="#写在前面的话" class="headerlink" title="写在前面的话"></a>写在前面的话</h3><blockquote>
<p>好久没有写博客了，不知道写点什么。正好要在公司分享技术，我就想到了好久之前看过的分布式事务的框架seata。趁着这个机会，查漏补缺，整理一篇博客出来，从理论到实战，让我对其设计思想，实际应用又更多一分认识。</p>
</blockquote>
<h3 id="什么是Seata"><a href="#什么是Seata" class="headerlink" title="什么是Seata?"></a>什么是Seata?</h3><ul>
<li>Seata 是一款开源的分布式事务解决方案，致力于提供高性能和简单易用的分布式事务服务。Seata 将为用户提供了 AT、TCC、SAGA 和 XA 事务模式，为用户打造一站式的分布式解决方案。 </li>
</ul>
<h4 id="Seata术语"><a href="#Seata术语" class="headerlink" title="Seata术语"></a>Seata术语</h4><ul>
<li>TC (Transaction Coordinator) - 事务协调者： 维护全局和分支事务的状态，驱动全局事务提交或回滚。 </li>
<li>TM (Transaction Manager) - 事务管理器： 定义全局事务的范围：开始全局事务、提交或回滚全局事务。 </li>
<li>RM (Resource Manager) - 资源管理器： 管理分支事务处理的资源，与TC交谈以注册分支事务和报告分支事务的状态，并驱动分支事务提交或回滚。 </li>
</ul>
<h3 id="事务模式-AT模式"><a href="#事务模式-AT模式" class="headerlink" title="事务模式-AT模式"></a>事务模式-AT模式</h3><p><strong>本质是对两阶段提交协议的演变</strong></p>
<ul>
<li>一阶段：业务数据和回滚的日志记录在同一个本地事务中提交。</li>
<li>二阶段：<ul>
<li>提交异步化</li>
<li>如果发生异常，回滚通过一阶段提交的回滚日志进行反向补偿</li>
</ul>
</li>
</ul>
<h4 id="写隔离-重要"><a href="#写隔离-重要" class="headerlink" title="写隔离 (重要)"></a>写隔离 <font style="color:red;">(重要)</font></h4><ul>
<li>一阶段提交本地事务需要拿到<strong>全局锁</strong></li>
<li>二阶段全局回滚需要拿到对应分支数据的<strong>本地锁</strong></li>
</ul>
<p>这里拿官方文档的示例说明（不是我懒，官方的图挺好的）:</p>
<ul>
<li>这里有两个全局事务，<code>tx1</code>和<code>tx2</code>，分别对一张表的m字段进行更新操作</li>
<li>由图可知，<code>tx1</code>先开启本地事务拿本地锁，执行更新操作<code>update a set m = m - 100 where id = 1</code>。然后获取全局锁。如果拿到全局事务锁，就提交本地事务，释放本地锁。此后<code>tx2</code>开启事务，执行更新操作，然后尝试去获取<code>全局锁</code>，此时<code>全局锁</code>被<code>tx1</code>持有，于是<code>tx2</code>就进行重试并等待<code>全局锁</code>。</li>
</ul>
<p><img src="https://img.alicdn.com/tfs/TB1zaknwVY7gK0jSZKzXXaikpXa-702-521.png" alt=""></p>
<ul>
<li><code>tx1</code>二阶段全局提交，释放<code>全局锁</code>，然后<code>tx2</code>才能拿到<code>全局锁</code>提交本地事务</li>
</ul>
<p><img src="https://img.alicdn.com/tfs/TB1xW0UwubviK0jSZFNXXaApXXa-718-521.png" alt=""></p>
<ul>
<li><p>如果<code>tx1</code>的二阶段全局回滚，那么<code>tx1</code>需要重新获取其数据（对应分支）的本地锁进行反向补偿。这时如果<code>tx2</code>还在等待全局锁，同时持有本地锁，那么<code>tx1</code>拿不到对应数据的本地锁的本地分支就会回滚失败。分支的回滚就会进行重试，直到<code>tx2</code>的全局锁获取等待超时，于是放弃全局锁，并回滚本地事务释放本地锁，这时<code>tx1</code>拿到本地锁就回滚成功。</p>
</li>
<li><p>由于整个过程<code>tx1</code>一直持有<code>全局锁</code>，所以不会发生<code>赃写</code>的问题</p>
</li>
</ul>
<h4 id="读隔离-重要"><a href="#读隔离-重要" class="headerlink" title="读隔离 (重要)"></a>读隔离 <font style="color:red;">(重要)</font></h4><ul>
<li>在数据库本地事务隔离级别 <strong>读已提交（Read Committed）</strong> 或以上的基础上，<code>Seata（AT 模式）</code>的默认全局隔离级别是 <strong>读未提交（Read Uncommitted）</strong> 。如果应用在特定场景下，必需要求全局的 <strong>读已提交</strong> ，目前 <code>Seata</code> 的方式是通过 <code>SELECT FOR UPDATE</code> 语句的代理。</li>
</ul>
<p><img src="https://img.alicdn.com/tfs/TB138wuwYj1gK0jSZFuXXcrHpXa-724-521.png" alt=""></p>
<ul>
<li>如图所示，执行<code>select for update</code>时会申请全局锁，如果全局锁被其他事务持有，则释放本地锁并重试。整个过程，查询是<code>block</code>的，直到拿到全局锁。即读取到的数据是<code>已提交</code>的，才将数据返回。</li>
</ul>
<h4 id="工作机制"><a href="#工作机制" class="headerlink" title="工作机制"></a>工作机制</h4><p>以一个示例来说明整个 AT 分支的工作过程。</p>
<p>业务表：<code>product</code></p>
<table>
<thead>
<tr>
<th align="center">Field</th>
<th align="center">Type</th>
<th align="center">Key</th>
</tr>
</thead>
<tbody><tr>
<td align="center">id</td>
<td align="center">bigint(20)</td>
<td align="center">PRI</td>
</tr>
<tr>
<td align="center">name</td>
<td align="center">varchar(100)</td>
<td align="center"></td>
</tr>
<tr>
<td align="center">since</td>
<td align="center">varchar(100)</td>
<td align="center"></td>
</tr>
</tbody></table>
<p>AT 分支事务的业务逻辑：</p>
<pre><code class="mysql">update product set name = &#39;GTS&#39; where name = &#39;TXC&#39;;</code></pre>
<h4 id="一阶段"><a href="#一阶段" class="headerlink" title="一阶段"></a>一阶段</h4><ol>
<li><p>解析 SQL：得到 SQL 的类型（UPDATE），表（product），条件（where name = ‘TXC’）等相关的信息。</p>
</li>
<li><p>查询前镜像：根据解析得到的条件信息，生成查询语句，定位数据。</p>
<pre><code class="mysql">select id, name, since from product where name = &#39;TXC&#39;;

## 得到修改前的镜像
{
 id: 1,
 name: TXC,
 since: 2014
}</code></pre>
<p>得到前镜像</p>
</li>
<li><p>执行业务 SQL：更新这条记录的 name 为 ‘GTS’。</p>
</li>
<li><p>查询后镜像：根据前镜像的结果，通过 <strong>主键</strong> 定位数据。</p>
<pre><code class="mysql">select id, name, since from product where id = 1`;

## 得到修改后的镜像
{
 id: 1,
 name: GTS,
 since: 2014
}</code></pre>
</li>
<li><p>插入回滚日志：把前后镜像数据以及业务 SQL 相关的信息组成一条回滚日志记录，插入到 <code>UNDO_LOG</code> 表中。</p>
<pre><code class="json">{
    &quot;branchId&quot;: 641789253,
    &quot;undoItems&quot;: [{
        &quot;afterImage&quot;: {
            &quot;rows&quot;: [{
                &quot;fields&quot;: [{
                    &quot;name&quot;: &quot;id&quot;,
                    &quot;type&quot;: 4,
                    &quot;value&quot;: 1
                }, {
                    &quot;name&quot;: &quot;name&quot;,
                    &quot;type&quot;: 12,
                    &quot;value&quot;: &quot;GTS&quot;
                }, {
                    &quot;name&quot;: &quot;since&quot;,
                    &quot;type&quot;: 12,
                    &quot;value&quot;: &quot;2014&quot;
                }]
            }],
            &quot;tableName&quot;: &quot;product&quot;
        },
        &quot;beforeImage&quot;: {
            &quot;rows&quot;: [{
                &quot;fields&quot;: [{
                    &quot;name&quot;: &quot;id&quot;,
                    &quot;type&quot;: 4,
                    &quot;value&quot;: 1
                }, {
                    &quot;name&quot;: &quot;name&quot;,
                    &quot;type&quot;: 12,
                    &quot;value&quot;: &quot;TXC&quot;
                }, {
                    &quot;name&quot;: &quot;since&quot;,
                    &quot;type&quot;: 12,
                    &quot;value&quot;: &quot;2014&quot;
                }]
            }],
            &quot;tableName&quot;: &quot;product&quot;
        },
        &quot;sqlType&quot;: &quot;UPDATE&quot;
    }],
    &quot;xid&quot;: &quot;xid:xxx&quot;
}</code></pre>
</li>
<li><p>提交前，向 <code>TC</code> 注册分支：申请 <code>product</code> 表中，主键值等于 1 的记录的 <strong>全局锁</strong> 。</p>
</li>
<li><p>本地事务提交：业务数据的更新和前面步骤中生成的 <code>UNDO LOG</code> 一并提交。</p>
</li>
<li><p>将本地事务提交的结果上报给 <code>TC</code>。</p>
</li>
</ol>
<h4 id="二阶段-回滚"><a href="#二阶段-回滚" class="headerlink" title="二阶段-回滚"></a>二阶段-回滚</h4><ol>
<li><p>收到 <code>TC</code>的分支回滚请求，开启一个本地事务，执行如下操作。</p>
</li>
<li><p>通过<code>XID</code> 和<code>Branch ID</code> 查找到相应的 <code>UNDO LOG</code> 记录。</p>
</li>
<li><p>数据校验：拿 <code>UNDO LOG</code> 中的后镜与当前数据进行比较，如果有不同，说明数据被当前全局事务之外的动作做了修改。这种情况，需要根据配置策略来做处理，详细的说明在另外的文档中介绍。</p>
</li>
<li><p>根据 <code>UNDO LOG</code> 中的前镜像和业务 <code>SQL</code> 的相关信息生成并执行回滚的语句：</p>
<pre><code class="mysql">update product set name = &#39;TXC&#39; where id = 1;</code></pre>
</li>
<li><p>提交本地事务。并把本地事务的执行结果（即分支事务回滚的结果）上报给 TC。</p>
</li>
</ol>
<h4 id="二阶段-提交"><a href="#二阶段-提交" class="headerlink" title="二阶段-提交"></a>二阶段-提交</h4><ol>
<li>收到 <code>TC</code> 的分支提交请求，把请求放入一个异步任务的队列中，马上返回提交成功的结果给 TC。</li>
<li>异步任务阶段的分支提交请求将异步和批量地删除相应 <code>UNDO LOG</code>记录。</li>
</ol>
<h3 id="项目实战"><a href="#项目实战" class="headerlink" title="项目实战"></a>项目实战</h3><blockquote>
<p>这里只是简单的使用。注册中心采用eureka，网关使用gateway，rpc使用<code>feign</code></p>
</blockquote>
<h4 id="工程结构"><a href="#工程结构" class="headerlink" title="工程结构"></a>工程结构</h4><pre><code class="shell">├─account-service    -- 账户服务 --
├─eureka-server      -- 注册中心 -- 
├─gateway-service    -- 网关服务 -- 
├─goods-service      -- 商品服务 --
└─order-service      -- 订单服务 --</code></pre>
<h4 id="建表语句"><a href="#建表语句" class="headerlink" title="建表语句"></a>建表语句</h4><h5 id="业务sql"><a href="#业务sql" class="headerlink" title="业务sql"></a>业务sql</h5><pre><code class="mysql">create table account
(
    id         bigint unsigned not null primary key auto_increment comment &#39;主键id&#39;,
    money      decimal(11, 2)  not null default 0 comment &#39;账户余额&#39;,
    gmt_create timestamp       not null default current_timestamp comment &#39;创建时间&#39;,
    gmt_modify timestamp       not null default current_timestamp on update current_timestamp comment &#39;修改时间&#39;
) comment &#39;账户表&#39;;

create table goods
(
    id         bigint unsigned not null primary key auto_increment comment &#39;主键id&#39;,
    name       varchar(32)     not null default &#39;&#39; comment &#39;商品名称&#39;,
    stock      int unsigned    not null default 0 comment &#39;库存数量&#39;,
    price      decimal(11, 2)  not null default 0 comment &#39;商品价格&#39;,
    gmt_create timestamp       not null default current_timestamp comment &#39;创建时间&#39;,
    gmt_modify timestamp       not null default current_timestamp on update current_timestamp comment &#39;修改时间&#39;
) comment &#39;商品表&#39;;

create table order_detail
(
    id         bigint unsigned not null primary key auto_increment comment &#39;主键id&#39;,
    goods_id   bigint unsigned not null comment &#39;商品id&#39;,
    account_id bigint unsigned not null comment &#39;账户id&#39;,
    price      decimal(11, 2)  not null default 0 comment &#39;订单价格&#39;,
    amount     int unsigned    not null default 1 comment &#39;商品数量&#39;,
    gmt_create timestamp       not null default current_timestamp comment &#39;创建时间&#39;,
    gmt_modify timestamp       not null default current_timestamp on update current_timestamp comment &#39;修改时间&#39;
) comment &#39;订单表&#39;;

insert into account(money)
values (10000);
insert into goods(name, stock, price)
values (&#39;华为Meta 30&#39;, 10, 5000.00);</code></pre>
<h5 id="回滚日志表"><a href="#回滚日志表" class="headerlink" title="回滚日志表"></a>回滚日志表</h5><pre><code class="mysql">CREATE TABLE `undo_log`
(
    `id`            bigint(20)   NOT NULL AUTO_INCREMENT,
    `branch_id`     bigint(20)   NOT NULL comment, 
    `xid`           varchar(100) NOT NULL,
    `context`       varchar(128) NOT NULL,
    `rollback_info` longblob     NOT NULL,
    `log_status`    int(11)      NOT NULL,
    `log_created`   datetime     NOT NULL,
    `log_modified`  datetime     NOT NULL,
    PRIMARY KEY (`id`),
    UNIQUE KEY `ux_undo_log` (`xid`, `branch_id`)
) ENGINE = InnoDB AUTO_INCREMENT = 1 DEFAULT CHARSET = utf8;</code></pre>
<h4 id="项目配置文件"><a href="#项目配置文件" class="headerlink" title="项目配置文件"></a>项目配置文件</h4><p><code>application.yml</code></p>
<pre><code class="yaml"># 在项目中加入seata的事务分组配置
spring:  
  cloud:
    alibaba:
      seata:
        tx-service-group: eyestarrysky-seata</code></pre>
<p>在<code>Seata</code>项目提供的<code>file.conf</code>中加入如下配置</p>
<pre><code class="properties">## transaction log store
store {
  # 修改数据库配置
  ## database store
  db {
    datasource = &quot;druid&quot;
    db-type = &quot;mysql&quot;
    driver-class-name = &quot;com.mysql.jdbc.Driver&quot;
    url = &quot;jdbc:mysql://xxx:3306/seata&quot;
    user = &quot;xxx&quot;
    password = &quot;xxx&quot;
  }

}
service {
  # 这里记得配置事务分组(eyestarrysky-seata)
  vgroup_mapping.eyestarrysky-seata = &quot;default&quot;
  default.grouplist = &quot;127.0.0.1:8091&quot;
  enableDegrade = false
  # disable seata
  disableGlobalTransaction = false
}</code></pre>
<h4 id="项目启动"><a href="#项目启动" class="headerlink" title="项目启动"></a>项目启动</h4><ul>
<li><p>启动<code>seata-server</code> </p>
</li>
<li><p>依次启动<strong>注册中心</strong>，<strong>网关中心</strong>和<strong>业务工程</strong></p>
</li>
</ul>
<h4 id="业务流程"><a href="#业务流程" class="headerlink" title="业务流程"></a>业务流程</h4><ul>
<li>下图解释了<code>TC</code>，<code>TM</code>，<code>RM</code>在项目中的具体角色和业务流程 （<a href="#Seata术语">名词解释</a>）</li>
</ul>
<p><img src="http://qiniu.eyestarrysky.top/seata%E5%9B%BE%E7%89%87.png" alt="原谅我手残"></p>
<ol>
<li>调用订单服务下单接口</li>
<li>订单服务调用商品服务检查库存</li>
<li>订单服务调用账户服务检查账户余额</li>
<li>本地事务-生成订单</li>
<li>远程事务扣减库存</li>
<li>账户服务扣减账户余额</li>
</ol>
<ul>
<li>简单看下代码，使用非常方便，在<code>OrderService</code>中的提交订单方法上加 <font style="color:red"><code>@GlobalTransactional</code></font>注解，<code>name</code>的值应该填充为<code>application.yml</code>中配置的事务分组名称<strong>eyestarrysky-seata</strong>，<code>flag</code>字段方便我在测试接口时控制提交，和回滚</li>
</ul>
<pre><code class="java">@GlobalTransactional(name = &quot;eyestarrysky-seata&quot;, rollbackFor = Exception.class)
public void submitOrder(Long goodsId, Long accountId, Integer amount, Integer flag) {
    //查询商品
    Goods goods = goodsClient.findById(goodsId);
    if (goods == null) {
        throw new IllegalArgumentException(&quot;商品数据找不到&quot;);
    }
    if (goods.getStock() &lt; amount) {
        log.warn(&quot;【生成订单失败，商品库存不足】商品信息: {}, 购买数量amount = {}&quot;, JSON.toJSONString(goods), amount);
        return;
    }
    BigDecimal orderPrice = goods.getPrice().multiply(BigDecimal.valueOf(amount));

    Account account = accountClient.findOneAccount(accountId);
    if (account == null) {
        throw new IllegalArgumentException(&quot;账户找不到&quot;);
    }
    if (account.getMoney().compareTo(orderPrice) &lt; 0) {
        log.warn(&quot;【生成订单失败，账户余额不足】账户余额: {}, 订单总额amount = {}&quot;, account.getMoney(), orderPrice);
        return;
    }
    OrderDetail orderDetail = new OrderDetail();
    orderDetail.setAccountId(accountId);
    orderDetail.setAmount(amount);
    orderDetail.setGoodsId(goodsId);
    orderDetail.setPrice(orderPrice);
    //1.本地事务-扣减库存
    orderDetailMapper.insert(orderDetail);

    //2. 远程事务-扣减库存
    goodsClient.reduceStock(goodsId, amount);
    //3. 远程事务-扣减余额
    accountClient.deductionMoney(accountId, orderPrice);

    if (flag &gt; 0) {
        log.error(&quot;【发生异常，事务回滚】&quot;);
        throw new RuntimeException(&quot;回滚事务&quot;);
    }
}</code></pre>
<h4 id="事务执行中的数据情况"><a href="#事务执行中的数据情况" class="headerlink" title="事务执行中的数据情况"></a>事务执行中的数据情况</h4><ul>
<li><p>商品数据</p>
<pre><code class="json">{
    &quot;id&quot;: 1,
    &quot;price&quot;: 5000
    &quot;stock&quot;: 6
}</code></pre>
</li>
<li><p>账户数据</p>
<pre><code class="json">{
    &quot;id&quot;: 1,
    &quot;money&quot;: 30000.00,
    &quot;gmtCreate&quot;: &quot;2020-09-08T17:26:44.000+00:00&quot;,
    &quot;gmtModify&quot;: &quot;2021-05-28T08:56:33.000+00:00&quot;
}</code></pre>
</li>
</ul>
<h5 id="正常下单"><a href="#正常下单" class="headerlink" title="正常下单"></a>正常下单</h5><pre><code class="json"># 购买商品一件，订单正常生成
# 商品
{
    &quot;id&quot;: 1,
    &quot;price&quot;: 5000
    &quot;stock&quot;: 5
}

# 账户
{
    &quot;id&quot;: 1,
    &quot;money&quot;: 25000.00,
    &quot;gmtCreate&quot;: &quot;2020-09-08T17:26:44.000+00:00&quot;,
    &quot;gmtModify&quot;: &quot;2021-05-28T08:56:33.000+00:00&quot;
}</code></pre>
<h5 id="日志打印"><a href="#日志打印" class="headerlink" title="日志打印"></a>日志打印</h5><pre><code class="json"># 订单生成前，开启事务，并生成xid 
i.seata.tm.api.DefaultGlobalTransaction  : Begin new global transaction [172.17.0.2:8091:141593301408030720]
# 生成订单完成 --&gt; 扣减商品库存前
# 此时undo_log表里面写入一条数据
{
    &quot;branch_id&quot;: 141593374497972224,
    &quot;xid&quot;: &quot;172.17.0.2:8091:141593301408030720&quot;,
    &quot;rollback_info&quot;: &quot;xxx&quot;
}

# 扣减库存完成，undo_log表多了一条数据,xid是相同的
{
    &quot;branch_id&quot;: 141594493718634496,
    &quot;xid&quot;: &quot;172.17.0.2:8091:141593301408030720&quot;,
    &quot;rollback_info&quot;: &quot;xxx&quot;
}</code></pre>
<h5 id="订单下单失败的情况"><a href="#订单下单失败的情况" class="headerlink" title="订单下单失败的情况"></a>订单下单失败的情况</h5><ul>
<li>这里我简单的测试了3种情况<ol>
<li>下单超时情况（全局事务未提交前），回滚成功</li>
<li>本地事务发生异常，回滚成功</li>
<li>分支事务发生异常，回滚成功</li>
</ol>
</li>
</ul>
<h3 id="写在最后"><a href="#写在最后" class="headerlink" title="写在最后"></a>写在最后</h3><ul>
<li>这篇文章只是对<code>seata</code>的简单介绍和应用，后面我会另写一篇文章（埋个坑）来从源码的角度更深入地分析，<code>seata</code>是如何处理分布式事务的。</li>
</ul>
]]></content>
      <categories>
        <category>分布式事务</category>
      </categories>
      <tags>
        <tag>seata</tag>
        <tag>分布式事务</tag>
      </tags>
  </entry>
  <entry>
    <title>温故知新-redis过期策略及应用</title>
    <url>/2020/05/24/%E6%B8%A9%E6%95%85%E7%9F%A5%E6%96%B0-redis%E8%BF%87%E6%9C%9F%E7%AD%96%E7%95%A5%E5%8F%8A%E5%BA%94%E7%94%A8/</url>
    <content><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><ul>
<li>当人们在过五一长假时<code>Redis 6.0</code>悄然发布了，这个版本提供了许多新特性和一些功能上的改进，其中最引入关注的当属“多线程”了。但是，本文先不谈新特性，先对本人学过的<code>redis</code>相关知识及应用做一下回顾，以后抽空会再写一篇我对<code>Redis 6.0</code>的所知所学</li>
</ul>
<h3 id="Redis的过期策略是什么"><a href="#Redis的过期策略是什么" class="headerlink" title="Redis的过期策略是什么"></a>Redis的过期策略是什么</h3><h4 id="过期策略"><a href="#过期策略" class="headerlink" title="过期策略"></a>过期策略</h4><ul>
<li>解答是<code>定期删除</code> +  <code>惰性删除</code><ul>
<li><code>定期删除</code>指的是<code>redis</code>默认每隔<code>100ms</code>就随机抽取一些设置了过期时间的key，检查其是否过期，如果过期就删除</li>
<li>由于定期删除可能会导致key到过期时间了，没有被随机抽取删除掉，所以有了<code>惰性删除</code>，当使用获取key操作时，<code>redis</code>会检查key是否过期，如果过期了就删除掉不会返回任何东西</li>
</ul>
</li>
</ul>
<p><strong>但是如果某个key一直没有获取操作或者被定期删除随机抽取到，那么也会堆积大量key在内存里，所以有了内存淘汰机制</strong></p>
<h4 id="内存淘汰机制"><a href="#内存淘汰机制" class="headerlink" title="内存淘汰机制"></a>内存淘汰机制</h4><p><strong>redis 内存淘汰机制有以下几个：</strong></p>
<ul>
<li><code>noeviction</code>: 当内存不足以容纳新写入数据时，新写入操作会报错，这个一般没人用吧，实在是太恶心了。</li>
<li><code>allkeys-lru</code>：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）。</li>
<li><code>allkeys-random</code>：当内存不足以容纳新写入数据时，在键空间中，随机移除某个 key，这个一般没人用吧，为啥要随机，肯定是把最近最少使用的 key 给干掉啊。</li>
<li><code>volatile-lru</code>：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的 key（这个一般不太合适）。</li>
<li><code>volatile-random</code>：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个 key。</li>
<li><code>volatile-ttl</code>：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的 key 优先移除。</li>
</ul>
<h3 id="实战演练"><a href="#实战演练" class="headerlink" title="实战演练"></a>实战演练</h3><blockquote>
<p>我在公司负责过一个直播项目，主播会提前预约一个直播间，然后把直播间通过社交软件分享出去吸引流量；如果预约时间过了10分钟还没有来开播，那么会删除直播间 + 七牛直播云关闭<code>Stream</code> + <code>imId</code>（当然，到了预约时间提前10分钟会push给主播提醒他开播，这些跟本文无关就不提了 )。</p>
</blockquote>
<h4 id="解决方案选择"><a href="#解决方案选择" class="headerlink" title="解决方案选择"></a>解决方案选择</h4><ol>
<li>使用<code>MQ</code>的延时消息来做，但是当时研究发现<code>RocketMQ</code>只支持指定的延时级别1s, 2s, … , 2h，没办法指定到具体的时间，其实这一点也能想到，RocketMQ作为一个高吞吐，低延时的消息队列，不设计这种具体到指定时间的延时消息也情有可原，因为这样就要在对消息排序上做大量处理，会极大地影响性能。于是 ，此方案不予采用。</li>
<li>采用定时任务来做，但是这样会很纠结这个定时任务的轮询时间，5分钟1次？2分钟1次？这样也没办法指定到具体时间，思来想去总觉得这个方案不太优雅，嗯，弃用。</li>
<li>自己实现一个时间轮？嗯，因为之前自己实现过一个时间轮，就拷贝到项目中使用，效果还不错，但是由于任务是放在内存中的，项目一重启，或者其他原因故障会导致任务丢失。这样一来那些空无一人的直播间挂在我们的直播首页也不太美观。于是考虑到要对任务做持久化，嗯，这样复杂度越来越高，而且还要新增业务表；于是乎，此方案也不采用。</li>
<li>最后是采用监听<code>redis</code> 的key过期事件来处理这个问题：将直播间<code>roomId:</code>做为key前缀，<code>expireTime</code> = 预约开播时间 + 10分钟 - 当前时间。当监听到指定key过期时，调用指定业务方法区处理。这样一来不需要引入额外的中间件，编码复杂度低，处理时间十分精确，完美地解决问题。</li>
</ol>
<h4 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h4><ul>
<li><strong><font style="color:red;">注意：需要开启<code>Redis</code> key 过期提醒，在<code>redis.conf</code>中加入<code>notify-keyspace-events Ex</code>配置 </font></strong></li>
</ul>
<h5 id="配置类"><a href="#配置类" class="headerlink" title="配置类"></a>配置类</h5><pre><code class="java">@Configuration
public class RedisConfig {

    @Bean
    public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory factory) {
        RedisTemplate&lt;String, Object&gt; template = new RedisTemplate&lt;&gt;();
        template.setConnectionFactory(factory);
        // 设置key的序列化方式
        template.setKeySerializer(RedisSerializer.string());
        // 设置value的序列化方式
        template.setValueSerializer(RedisSerializer.json());
        // 设置hash的key的序列化方式
        template.setHashKeySerializer(RedisSerializer.string());
        // 设置hash的value的序列化方式
        template.setHashValueSerializer(RedisSerializer.json());
        template.afterPropertiesSet();
        return template;
    }

    /**
     * 将redis消息监听器注册为一个bean
     * @param connectionFactory 链接工厂
     * @return RedisMessageListenerContainer
     */
    @Bean
    public RedisMessageListenerContainer container(RedisConnectionFactory connectionFactory) {
        RedisMessageListenerContainer container = new RedisMessageListenerContainer();
        container.setConnectionFactory(connectionFactory);
        return container;
    }
}</code></pre>
<h5 id="key过期监听类"><a href="#key过期监听类" class="headerlink" title="key过期监听类"></a>key过期监听类</h5><pre><code class="java">@Slf4j
@Component
public class RedisKeyExpirationListener extends KeyExpirationEventMessageListener {

    public RedisKeyExpirationListener(RedisMessageListenerContainer listenerContainer) {
        super(listenerContainer);
    }

    @Override
    public void onMessage(Message message, byte[] pattern) {
        //获取失效的key, 进行对应的业务处理
        String expiredKey = message.toString();
        //取redis前缀符合的进行乡音处理
        if (expiredKey.startsWith(RedisKeyConstant.LIVE_ROOM_CLOSE)) {
            log.info(&quot;【这里进行对应的业务处理】, 业务key = {}过期&quot;, expiredKey);
        }
    }
}</code></pre>
<h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><blockquote>
<p>​        其实，我这里的实战演练中的业务对时间点选择不是那么敏感，采用定时任务去处理，稍微晚那么几分钟关闭过期未及时开播的直播间也未尝不可，只是我个人是觉得监听redis key过期的方案更优雅，实现也简单罢了。其实这种方案适合很多种场景，比如订单30分钟超时未支付取消订单也非常适合使用。在未来我也会对自己所知所学多做总结，希望能做到温故知新，在日常学习中提升技术广度，在工作中践行技术深度，自我勉励！</p>
</blockquote>
]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
</search>
