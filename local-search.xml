<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>分布式协议与算法</title>
    <link href="/2020/09/05/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%AE%AE%E4%B8%8E%E7%AE%97%E6%B3%95/"/>
    <url>/2020/09/05/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%AE%AE%E4%B8%8E%E7%AE%97%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><blockquote><p>为了对分布式系统有更深的理解，也为了我的技术成长提供更多可能性，我花了部分时间对目前分布式系统设计中比较常用或者重要的算法进行了学习，最终整理出这篇文章。以前学习时，对于分布式，高可用，集群，leader选举等一系列核心问题都是一知半解，希望日后我也能时常勉励自己，有时间可以再回过头来看看这篇博客，做到见微知著，举一反三。</p></blockquote><h3 id="Paxos算法简介"><a href="#Paxos算法简介" class="headerlink" title="Paxos算法简介"></a>Paxos算法简介</h3><ul><li><p>我看了很多文章，对于<code>Paxos</code>算法还是一知半解，所以这里只是对<code>Paxos</code>算法做简单的总结。</p></li><li><p><code>Paxos</code>算法包含两个重要部分</p><ol><li><code>Basic-Paxos</code>算法，描述的是多节点之间如何就某个提案达成共识</li><li><code>Muti-Paxos</code>算法，描述的是执行多个<code>Basic-Paxos</code>实例，就一系列提案达成共识。下面要说的的<code>Raft</code>算法就是基于<code>Multi-Paxos</code>思想的共识算法之一。</li></ol></li></ul><h3 id="Raft算法"><a href="#Raft算法" class="headerlink" title="Raft算法"></a>Raft算法</h3><ul><li><code>Raft</code>算法是现在分布式系统开发首选的共识算法。</li><li><code>Raft</code>算法是强领导者模型，集群中只能有一个<code>Leader</code></li></ul><h4 id="成员身份"><a href="#成员身份" class="headerlink" title="成员身份"></a>成员身份</h4><ol><li><code>Follower</code>：接收和处理来自<code>Leader</code>的消息，跟<code>Leader</code>心跳超时时，就变为<code>Candidate</code></li><li><code>Candidate</code>：候选人向其他节点发送<code>RPC</code>消息请求投票，通知它们投票，如果赢得了大多数选票就晋升为<code>Leader</code></li><li><code>Leader</code>：处理写请求，管理日志复制和不断发送心跳消息，通知其他节点。</li></ol><h4 id="Leader选举"><a href="#Leader选举" class="headerlink" title="Leader选举"></a>Leader选举</h4><ul><li>初始状态时，集群中所有的节点都是跟随者的状态。<code>Raft</code>实现了随机超时时间的特性，每个节点等待领导者节点心跳信息的超时时间间隔是随机的。可以看到，下图中节点A会最先因为没有收到<code>leader</code>心跳信息发生超时。这个时候节点A就会增加自己的任期编号，并且推举自己为<code>Candidate</code>，并给自己投上一票，然后向其他节点发送<code>RPC</code>请求投票。</li></ul><p><img src="../image/Raft%E7%AE%97%E6%B3%95-Leader%E9%80%89%E4%B8%BE1.png" alt=""></p><ul><li><p>其他节点收到候选者A的投票请求，在编号为1的这届任期没有进行过投票，那么它将把选票投给A，并增加自己的任期编号。</p></li><li><p>如果候选人A在选举超时时间内赢得了大多数的选票，那么它就会成为本届任期内新的<code>Leader</code></p></li><li><p>节点A当选<code>Leader</code>后，他将周期性地发送心跳消息，通知其他服务器我是领导者，阻止跟随者发起新的选举</p></li></ul><h4 id="日志复制"><a href="#日志复制" class="headerlink" title="日志复制"></a>日志复制</h4><h5 id="日志的基本介绍"><a href="#日志的基本介绍" class="headerlink" title="日志的基本介绍"></a>日志的基本介绍</h5><blockquote><p>在 Raft 算法中，副本数据是以日志的形式存在的，领导者接收到来自客户端写请求后，处理写请求的过程就是一个复制和提交日志项的过程。</p></blockquote><ul><li><h5 id="日志由日志项组成。而日志项主要包含用户指定的数据，也就是指令（Command），还包含一些附加信息，比如索引值（Log-index）、任期编号（Term）。"><a href="#日志由日志项组成。而日志项主要包含用户指定的数据，也就是指令（Command），还包含一些附加信息，比如索引值（Log-index）、任期编号（Term）。" class="headerlink" title="日志由日志项组成。而日志项主要包含用户指定的数据，也就是指令（Command），还包含一些附加信息，比如索引值（Log index）、任期编号（Term）。"></a>日志由日志项组成。而日志项主要包含用户指定的数据，也就是指令（Command），还包含一些附加信息，比如索引值（Log index）、任期编号（Term）。</h5></li></ul><p><img src="../image/Raft%E6%97%A5%E5%BF%97%E9%A1%B9.png" alt=""></p><ul><li>需要注意的是，<strong><font style="color:red">一届Leader任期内，往往有多条日志项，而且日志项的索引值是连续的。</font></strong></li></ul><h5 id="日志复制的过程"><a href="#日志复制的过程" class="headerlink" title="日志复制的过程"></a>日志复制的过程</h5><ul><li><p>首先，领导者进入第一阶段，通过日志复制(AppendEntries) RPC 消息，将日志项复制到集群其他节点上。接着，如果领导者接收到大多数的”复制成功”响应后，它将日志项提交到它的状态机，并返回成功给客户端。如果领导者没有接收到大多数的”复制成功”响应，那么就返回错误给客户端。</p></li><li><p>具体而言会分为以下几步：</p><ol><li><code>Leader</code>基于客户端请求的指令，创建一个新的日志项，并附加到本地日志中。</li><li><code>Leader</code>通过日志复制<code>RPC</code>操作，将新的日志项复制到其他服务器。</li><li>当<code>Leader</code>将日志项，成功复制到大多数服务器上的时候，<code>Leader</code>会将这条日志项提交到它的状态机中。</li><li><code>Leader</code>将执行的结果返回给客户端。</li><li>当<code>Leader</code>接收到心跳信息，或者新的日志复制<code>RPC</code>消息后，如果<code>Followers</code>发现<code>Leader</code>已经提交了某条日志项，而它还没提交，那么它就将这条日志项提交到本机的状态机中。</li></ol></li></ul><h4 id="成员变更"><a href="#成员变更" class="headerlink" title="成员变更"></a>成员变更</h4><p>​        日常工作中服务器故障的情况偶尔也会出现，这时就要替换故障的服务器。如果遇到需要改变数据副本（服务器）数的情况，则需要增加或移除集群中的服务器，总的来说，在生产环境中集群的服务器数量是会发生变化的。</p><ul><li>集群的配置：集群中各节点地址的集合。比如节点A、B、C组成的集群，那么集群的配置就是[A、B、C]集合。</li></ul><h5 id="成员变更的带来的问题"><a href="#成员变更的带来的问题" class="headerlink" title="成员变更的带来的问题"></a>成员变更的带来的问题</h5><ul><li>在集群中进行成员变更的最大风险是，可能会同时出现 2 个领导者。比如在进行成员变更时，节点 A、B 和 C 之间发生了分区错误，节点 A、B 组成旧配置中的“大多数”，也就是变更前的 3 节点集群中的“大多数”，那么这时的领导者（节点 A）依旧是领导者。  另一方面，节点 C 和新节点 D、E 组成了新配置的“大多数”，也就是变更后的 5 节点集群中的“大多数”，它们可能会选举出新的领导者（比如节点 C）。那么这时，就出现了同时存在 2 个领导者的情况。 </li></ul><p><img src="../image/%E6%88%90%E5%91%98%E5%8F%98%E6%9B%B4%E5%A4%9Aleader.png" alt=""></p><h5 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h5><ul><li>通过单节点变更解决成员变更出现的极端情况。顾名思义，单节点变更就是通过一次变更一个节点实现成员变更。如果需要变更多个节点，就就行多次单节点变更。</li></ul><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><pre><code> **Raft 不是一致性算法而是共识算法，是一个 Multi-Paxos 算法，实现的是如何就一系列值达成共识。并且，Raft 能容忍少数节点的故障。虽然 Raft 算法能实现强一致性，也就是线性一致性（Linearizability），但需要客户端协议的配合。在实际场景中，我们一般需要根据场景特点，在一致性强度和实现复杂度之间进行权衡。比如 Consul 实现了三种一致性模型。** </code></pre><ul><li><p><code>default</code>：客户端访问领导者节点执行读操作，领导者确认自己处于稳定状态时（在 leader leasing 时间内），返回本地数据给客户端，否则返回错误给客户端。在这种情况下，客户端是可能读到旧数据的，比如此时发生了网络分区错误，新领导者已经更新过数据，但因为网络故障，旧领导者未更新数据也未退位，仍处于稳定状态。 </p></li><li><p><code>consistent</code>：客户端访问领导者节点执行读操作，领导者在和大多数节点确认自己仍是领导者之后返回本地数据给客户端，否则返回错误给客户端。在这种情况下，客户端读到的都是最新数据。 </p></li><li><p><code>stale</code>：从任意节点读数据，不局限于领导者节点，客户端可能会读到旧数据。 </p><p><strong>一般而言，在实际工程中，Consul 的 consistent 就够用了，可以不用线性一致性，只要能保证写操作完成后，每次读都能读到最新值就可以了。比如为了实现冥等操作，我们使用一个编号 (ID) 来唯一标记一个操作，并使用一个状态字段（nil/done）来标记操作是否已经执行，那么只要我们能保证设置了 ID 对应状态值为 done 后，能立即和一直读到最新状态值就可以了，也就通过防止操作的重复执行，实现了冥等性。</strong> </p></li></ul><p>​      *<em>总的来说，Raft 算法能很好地处理绝大部分场景的一致性问题，在设计分布式系统时，优先考虑 Raft 算法，当 Raft 算法不能满足现有场景需求时，再去调研其他共识算法。 *</em></p>]]></content>
    
    
    <categories>
      
      <category>分布式</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Keepalived软件架构</title>
    <link href="/2020/08/16/keepalived%E8%BD%AF%E4%BB%B6%E6%9E%B6%E6%9E%84/"/>
    <url>/2020/08/16/keepalived%E8%BD%AF%E4%BB%B6%E6%9E%B6%E6%9E%84/</url>
    
    <content type="html"><![CDATA[<h3 id="理论介绍"><a href="#理论介绍" class="headerlink" title="理论介绍"></a>理论介绍</h3><h4 id="Keepalived的简介"><a href="#Keepalived的简介" class="headerlink" title="Keepalived的简介"></a>Keepalived的简介</h4><p>​        <code>Keepalived</code>软件起初是专为<code>LVS</code>负载均衡软件设计的，用来管理并监控<code>LVS</code>集群系统中各个服务节点的状态，后来又加入了可以实现高可用的<code>VRRP</code>功能。因此，<code>Keepalived</code>除了能够管理<code>LVS</code>软件外，还可以作为其他服务（例如：<code>Nginx、Haproxy、MySQL</code>等）的高可用解决方案软件。</p><p>　　<code>Keepalived</code>软件主要是通过<code>VRRP</code>协议实现高可用功能的。<code>VRRP</code>是<code>Virtual Router RedundancyProtocol</code>(虚拟路由器冗余协议）的缩写，<code>VRRP</code>出现的目的就是为了解决静态路由单点故障问题的，它能够保证当个别节点宕机时，整个网络可以不间断地运行。</p><p>​        <strong>所以，<code>Keepalived</code> 一方面具有配置管理<code>LVS</code>的功能，同时还具有对<code>LVS</code>下面节点进行健康检查的功能，另一方面也可实现系统网络服务的高可用功能。</strong></p><h4 id="keepalived高可用故障切换转移原理"><a href="#keepalived高可用故障切换转移原理" class="headerlink" title="keepalived高可用故障切换转移原理"></a>keepalived高可用故障切换转移原理</h4><blockquote><p>​        <code>Keepalived</code>高可用服务对之间的故障切换转移，是通过<code>VRRP (Virtual Router Redundancy Protocol,虚拟路由器冗余协议）</code>来实现的。</p></blockquote><p>　　<strong>在 <code>Keepalived</code>服务正常工作时，主 Master节点会不断地向备节点发送（多播的方式）心跳消息，用以告诉备Backup节点自己还活看，当主 Master节点发生故障时，就无法发送心跳消息，备节点也就因此无法继续检测到来自主 Master节点的心跳了，于是调用自身的接管程序，接管主Master节点的 IP资源及服务。而当主 Master节点恢复时，备Backup节点又会释放主节点故障时自身接管的IP资源及服务，恢复到原来的备用角色。</strong></p><h4 id="什么是VRRP"><a href="#什么是VRRP" class="headerlink" title="什么是VRRP"></a>什么是VRRP</h4><ol><li>VRRP,全称 Virtual Router Redundancy Protocol,中文名为虚拟路由冗余协议，VRRP的出现是为了解决静态路由的单点故障。 </li><li>VRRP是通过一种竟选协议机制来将路由任务交给某台 VRRP路由器的。 </li><li>VRRP用 IP多播的方式（默认多播地址（224.0_0.18))实现高可用对之间通信。 </li><li>工作时主节点发包，备节点接包，当备节点接收不到主节点发的数据包的时候，就启动接管程序接管主节点的开源。备节点可以有多个，通过优先级竞选，但一般 Keepalived系统运维工作中都是一对。 </li><li>VRRP使用了加密协议加密数据，但Keepalived官方目前还是推荐用明文的方式配置认证类型和密码。 </li></ol><hr><h4 id="keepalived的工作原理"><a href="#keepalived的工作原理" class="headerlink" title="keepalived的工作原理"></a>keepalived的工作原理</h4><p><img src="http://qiniu.eyestarrysky.top/keepalived%E9%AB%98%E5%8F%AF%E7%94%A8.png" alt=""></p><p>​        <strong>Keepalived高可用对之间是通过 VRRP进行通信的， VRRP是遑过竞选机制来确定主备的，主的优先级高于备，因此，工作时主会优先获得所有的资源，备节点处于等待状态，当主挂了的时候，备节点就会接管主节点的资源，然后顶替主节点对外提供服务。</strong></p><p>　　<strong>在 Keepalived服务对之间，只有作为主的服务器会一直发送 VRRP广播包,告诉备它还活着，此时备不会枪占主，当主不可用时，即备监听不到主发送的广播包时，就会启动相关服务接管资源，保证业务的连续性.接管速度最快可以小于1秒。</strong></p><h3 id="实战演练"><a href="#实战演练" class="headerlink" title="实战演练"></a>实战演练</h3><h4 id="使用Keepalived配置实现虚拟IP在多服务器节点漂移"><a href="#使用Keepalived配置实现虚拟IP在多服务器节点漂移" class="headerlink" title="使用Keepalived配置实现虚拟IP在多服务器节点漂移"></a>使用Keepalived配置实现虚拟IP在多服务器节点漂移</h4><ul><li>这里为了节约成本和方便演示，我准备了两台服务器<code>Master 192.168.56.101, Backup 192.168.56.102</code></li></ul><h5 id="安装keepalived及其配置文件结构"><a href="#安装keepalived及其配置文件结构" class="headerlink" title="安装keepalived及其配置文件结构"></a>安装keepalived及其配置文件结构</h5><pre><code class="shell"># 服务器上安装keepalived[root@localhost ~]# yum install keepalived -y# 查看安装目录[root@localhost ~]# rpm -ql keepalived/etc/keepalived/etc/keepalived/keepalived.conf (主配置文件)/etc/sysconfig/keepalived/usr/bin/genhash/usr/lib/systemd/system/keepalived.service/usr/libexec/keepalived/usr/sbin/keepalived/usr/share/doc/keepalived-1.3.5................# 查看配置文件[root@localhost ~]# cat /etc/keepalived/keepalived.conf ! Configuration File for keepalived# 全局配置global_defs {   # 邮箱地址   notification_email {     acassen@firewall.loc     failover@firewall.loc     sysadmin@firewall.loc   }   notification_email_from Alexandre.Cassen@firewall.loc   smtp_server 192.168.200.1   smtp_connect_timeout 30   # 路由id   router_id LVS_DEVEL   vrrp_skip_check_adv_addr   # 严格的vrrp，建议关掉#   vrrp_strict#   vrrp_garp_interval 0#  vrrp_gna_interval 0}# vrrp实例 （名称随意换)vrrp_instance VI_1 {    # 说明实例为master节点    state MASTER    # 指定的网卡名称    interface eth0    virtual_router_id 51    # 优先值，越大则故障转移时被选中顶替master的几率越大    priority 100    advert_int 1    authentication {        auth_type PASS        auth_pass 1111    }    # 虚拟ip地址    virtual_ipaddress {        192.168.200.16        192.168.200.17        192.168.200.18    }}</code></pre><h5 id="Master节点配置"><a href="#Master节点配置" class="headerlink" title="Master节点配置"></a>Master节点配置</h5><pre><code class="shell">global_defs {   notification_email {     12345678@qq.com   }   notification_email_from 188275291160@163.com   smtp_server 192.168.56.1   smtp_connect_timeout 30   router_id Nginx # vrrp_skip_check_adv_addr # vrrp_strict # vrrp_garp_interval 0 # vrrp_gna_interval 0}vrrp_instance Nginx_1 {    state MASTER    # 网卡配置 ifconfig查看    interface enp0s3    virtual_router_id 51    priority 100    advert_int 1    authentication {        auth_type PASS        auth_pass 1111    }    virtual_ipaddress {        192.168.56.103    }}</code></pre><h5 id="Backup节点配置"><a href="#Backup节点配置" class="headerlink" title="Backup节点配置"></a>Backup节点配置</h5><pre><code class="shell">! Configuration File for keepalivedglobal_defs {   notification_email {     12345678@qq.com   }   notification_email_from 188275291160@163.com   smtp_server 192.168.56.1   smtp_connect_timeout 30   router_id Nginx # vrrp_skip_check_adv_addr # vrrp_strict # vrrp_garp_interval 0 # vrrp_gna_interval 0}# vrrp实例名要与Master一样vrrp_instance Nginx_1 {    state BACKUP    interface enp0s3  # router_id与master保持一样，说明是同一个vrrp instance    virtual_router_id 51  # 优先级比master低      priority 98    advert_int 1    authentication {        auth_type PASS        auth_pass 1111    }    virtual_ipaddress {        192.168.56.103    }}</code></pre><h5 id="启动Master-keepalived"><a href="#启动Master-keepalived" class="headerlink" title="启动Master keepalived"></a>启动Master keepalived</h5><pre><code class="shell">[root@localhost keepalived]# systemctl start keepalived[root@localhost keepalived]# tail -f /var/log/messagesAug 15 02:57:08 localhost Keepalived[14810]: Starting VRRP child process, pid=14812Aug 15 02:57:08 localhost Keepalived_healthcheckers[14811]: Opening file &#39;/etc/keepalived/keepalived.conf&#39;.Aug 15 02:57:08 localhost Keepalived_vrrp[14812]: Registering Kernel netlink reflectorAug 15 02:57:08 localhost Keepalived_vrrp[14812]: Registering Kernel netlink command channelAug 15 02:57:08 localhost Keepalived_vrrp[14812]: Registering gratuitous ARP shared channelAug 15 02:57:08 localhost Keepalived_vrrp[14812]: Opening file &#39;/etc/keepalived/keepalived.conf&#39;.Aug 15 02:57:08 localhost Keepalived_vrrp[14812]: VRRP_Instance(Nginx_1) removing protocol VIPs.Aug 15 02:57:08 localhost Keepalived_vrrp[14812]: Using LinkWatch kernel netlink reflector...Aug 15 02:57:08 localhost Keepalived_vrrp[14812]: VRRP sockpool: [ifindex(2), proto(112), unicast(0), fd(10,11)]Aug 15 02:57:09 localhost Keepalived_vrrp[14812]: VRRP_Instance(Nginx_1) Transition to MASTER STATEAug 15 02:57:10 localhost Keepalived_vrrp[14812]: VRRP_Instance(Nginx_1) Entering MASTER STATEAug 15 02:57:10 localhost Keepalived_vrrp[14812]: VRRP_Instance(Nginx_1) setting protocol VIPs.Aug 15 02:57:10 localhost Keepalived_vrrp[14812]: Sending gratuitous ARP on enp0s3 for 192.168.56.103Aug 15 02:57:10 localhost Keepalived_vrrp[14812]: VRRP_Instance(Nginx_1) Sending/queueing gratuitous ARPs on enp0s3 for 192.168.56.103Aug 15 02:57:10 localhost Keepalived_vrrp[14812]: Sending gratuitous ARP on enp0s3 for 192.168.56.103Aug 15 02:57:15 localhost Keepalived_vrrp[14812]: VRRP_Instance(Nginx_1) Sending/queueing gratuitous ARPs on enp0s3 for 192.168.56.103Aug 15 02:57:15 localhost Keepalived_vrrp[14812]: Sending gratuitous ARP on enp0s3 for 192.168.56.103# 使用ip a或者ip addr show查看有了192.168.56.103的虚拟ip[root@localhost keepalived]# ip a1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever    inet6 ::1/128 scope host        valid_lft forever preferred_lft forever2: enp0s3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000    link/ether 08:00:27:79:dc:34 brd ff:ff:ff:ff:ff:ff    inet 192.168.56.101/24 brd 192.168.56.255 scope global noprefixroute dynamic enp0s3       valid_lft 999sec preferred_lft 999sec    inet 192.168.56.103/32 scope global enp0s3       valid_lft forever preferred_lft forever    inet6 fe80::b1d0:38ea:6339:11f8/64 scope link noprefixroute        valid_lft forever preferred_lft forever# ping 发现虚拟ip能够提供服务了[root@localhost keepalived]# ping 192.168.56.103PING 192.168.56.103 (192.168.56.103) 56(84) bytes of data.64 bytes from 192.168.56.103: icmp_seq=1 ttl=64 time=0.082 ms64 bytes from 192.168.56.103: icmp_seq=2 ttl=64 time=0.035 ms64 bytes from 192.168.56.103: icmp_seq=3 ttl=64 time=0.036 ms64 bytes from 192.168.56.103: icmp_seq=4 ttl=64 time=0.037 ms64 bytes from 192.168.56.103: icmp_seq=5 ttl=64 time=0.072 ms64 bytes from 192.168.56.103: icmp_seq=6 ttl=64 time=0.036</code></pre><h5 id="启动Backup-keepalived"><a href="#启动Backup-keepalived" class="headerlink" title="启动Backup keepalived"></a>启动Backup keepalived</h5><pre><code class="shell"># VRRP_Instance(Nginx_1) Entering BACKUP STATE[root@localhost keepalived]# tail -f /var/log/messagesAug 15 03:03:53 localhost Keepalived_healthcheckers[13529]: Opening file &#39;/etc/keepalived/keepalived.conf&#39;.Aug 15 03:03:53 localhost Keepalived[13528]: Starting VRRP child process, pid=13530Aug 15 03:03:53 localhost Keepalived_vrrp[13530]: Registering Kernel netlink reflectorAug 15 03:03:53 localhost Keepalived_vrrp[13530]: Registering Kernel netlink command channelAug 15 03:03:53 localhost Keepalived_vrrp[13530]: Registering gratuitous ARP shared channelAug 15 03:03:53 localhost Keepalived_vrrp[13530]: Opening file &#39;/etc/keepalived/keepalived.conf&#39;.Aug 15 03:03:53 localhost Keepalived_vrrp[13530]: VRRP_Instance(Nginx_1) removing protocol VIPs.Aug 15 03:03:53 localhost Keepalived_vrrp[13530]: Using LinkWatch kernel netlink reflector...Aug 15 03:03:53 localhost Keepalived_vrrp[13530]: VRRP_Instance(Nginx_1) Entering BACKUP STATEAug 15 03:03:53 localhost Keepalived_vrrp[13530]: VRRP sockpool: [ifindex(2), proto(112), unicast(0), fd(10,11)]# 当master正常访问时，虚拟ip只会在master上，否则由backup顶上[root@localhost keepalived]# ip a1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00    inet 127.0.0.1/8 scope host lo       valid_lft forever preferred_lft forever    inet6 ::1/128 scope host        valid_lft forever preferred_lft forever2: enp0s3: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000    link/ether 08:00:27:b3:b2:ab brd ff:ff:ff:ff:ff:ff    inet 192.168.56.102/24 brd 192.168.56.255 scope global noprefixroute dynamic enp0s3       valid_lft 807sec preferred_lft 807sec    inet6 fe80::3ddc:9a9a:23b5:44b5/64 scope link noprefixroute        valid_lft forever preferred_lft forever</code></pre><h5 id="模拟Master宕机-恢复试验"><a href="#模拟Master宕机-恢复试验" class="headerlink" title="模拟Master宕机-恢复试验"></a>模拟Master宕机-恢复试验</h5><pre><code class="shell"># master重启, 或systemctl stop keepalived模拟宕机[root@localhost ~]# reboot# 查看backup日志，发现backup服务器进入MASTER STATE，同时绑定虚拟ip 192.168.56.103[root@localhost ~]# tail -f /var/log/messagesAug 15 20:38:09 localhost Keepalived_vrrp[13605]: VRRP_Instance(Nginx_1) Transition to MASTER STATEAug 15 20:38:10 localhost Keepalived_vrrp[13605]: VRRP_Instance(Nginx_1) Entering MASTER STATEAug 15 20:38:10 localhost Keepalived_vrrp[13605]: VRRP_Instance(Nginx_1) setting protocol VIPs.Aug 15 20:38:10 localhost Keepalived_vrrp[13605]: Sending gratuitous ARP on enp0s3 for 192.168.56.103Aug 15 20:38:10 localhost Keepalived_vrrp[13605]: VRRP_Instance(Nginx_1) Sending/queueing gratuitous ARPs on enp0s3 for 192.168.56.103Aug 15 20:38:10 localhost Keepalived_vrrp[13605]: Sending gratuitous ARP on enp0s3 for 192.168.56.103# 当原先的MASTER恢复后，查看日志，发现收到广播信息，另一台服务器优先级为100，再次恢复成Backup，同时removing protocols VIPs;[root@localhost ~]# tail -f /var/log/messagesAug 15 20:42:37 localhost Keepalived_vrrp[13605]: VRRP_Instance(Nginx_1) Received advert with higher priority 100, ours 98Aug 15 20:42:37 localhost Keepalived_vrrp[13605]: VRRP_Instance(Nginx_1) Entering BACKUP STATEAug 15 20:42:37 localhost Keepalived_vrrp[13605]: VRRP_Instance(Nginx_1) removing protocol VIPs.</code></pre><h4 id="如何修改keepalived日志存放位置"><a href="#如何修改keepalived日志存放位置" class="headerlink" title="如何修改keepalived日志存放位置"></a>如何修改keepalived日志存放位置</h4><pre><code class="shell">[root@localhost ~]# vim /etc/sysconfig/keepalived # Options for keepalived. See `keepalived --help&#39; output and keepalived(8) and# keepalived.conf(5) man pages for a list of all options. Here are the most# common ones :## --vrrp               -P    Only run with VRRP subsystem.# --check              -C    Only run with Health-checker subsystem.# --dont-release-vrrp  -V    Dont remove VRRP VIPs &amp; VROUTEs on daemon stop.# --dont-release-ipvs  -I    Dont remove IPVS topology on daemon stop.# --dump-conf          -d    Dump the configuration data.# --log-detail         -D    Detailed log messages.# --log-facility       -S    0-7 Set local syslog facility (default=LOG_DAEMON)## 默认的KEEPALIVED_OPTIONS=&quot;-D&quot;KEEPALIVED_OPTIONS=&quot;-D -d -S 0&quot;[root@localhost ~]# vim /etc/rsyslog.conf # Save boot messages also to boot.loglocal7.*                                                /var/log/boot.log  # 增加这一行配置local0.*                                             /usr/local/nginx/logs/keepalived.log[root@localhost ~]# systemctl restart rsyslog[root@localhost ~]# systemctl restart keepalived</code></pre><h4 id="Keepalived-Nginx高可用原理"><a href="#Keepalived-Nginx高可用原理" class="headerlink" title="Keepalived + Nginx高可用原理"></a><code>Keepalived + Nginx</code>高可用原理</h4><ul><li>关键点在于，如何使得keepalived知道nginx宕机了。可以写一个脚本监控nginx进程，如果nginx挂了，触发kill掉keepalived，使得VIPs转移到别的服务器，从而实现服务高可用。</li></ul><pre><code class="shell">[root@localhost shell]# vim nginx_health_check.sh#!/bin/bash#ps -ef | grep nginx | grep -v grep &amp;&gt; /dev/null# $?不为0（nginx未启动时为0）时杀掉keepalived进程if [ $? -ne 0]; then    killall keepalivedfi# 利用$?（获取上一个命令的退出状态，或者上一个函数的返回值。）, nginx未启动时ps -ef | grep nginx | grep -v grep &amp;&gt; /dev/null 返回1，否则返回0[root@localhost shell]# ps -ef | grep nginx | grep -v grep &amp;&gt; /dev/null[root@localhost shell]# echo $?1</code></pre>]]></content>
    
    
    <categories>
      
      <category>keepalived</category>
      
    </categories>
    
    
    <tags>
      
      <tag>keepalived</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>温故知新-redis过期策略及应用</title>
    <link href="/2020/05/24/%E6%B8%A9%E6%95%85%E7%9F%A5%E6%96%B0-redis%E8%BF%87%E6%9C%9F%E7%AD%96%E7%95%A5%E5%8F%8A%E5%BA%94%E7%94%A8/"/>
    <url>/2020/05/24/%E6%B8%A9%E6%95%85%E7%9F%A5%E6%96%B0-redis%E8%BF%87%E6%9C%9F%E7%AD%96%E7%95%A5%E5%8F%8A%E5%BA%94%E7%94%A8/</url>
    
    <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><ul><li>当人们在过五一长假时<code>Redis 6.0</code>悄然发布了，这个版本提供了许多新特性和一些功能上的改进，其中最引入关注的当属“多线程”了。但是，本文先不谈新特性，先对本人学过的<code>redis</code>相关知识及应用做一下回顾，以后抽空会再写一篇我对<code>Redis 6.0</code>的所知所学</li></ul><h3 id="Redis的过期策略是什么"><a href="#Redis的过期策略是什么" class="headerlink" title="Redis的过期策略是什么"></a>Redis的过期策略是什么</h3><h4 id="过期策略"><a href="#过期策略" class="headerlink" title="过期策略"></a>过期策略</h4><ul><li>解答是<code>定期删除</code> +  <code>惰性删除</code><ul><li><code>定期删除</code>指的是<code>redis</code>默认每隔<code>100ms</code>就随机抽取一些设置了过期时间的key，检查其是否过期，如果过期就删除</li><li>由于定期删除可能会导致key到过期时间了，没有被随机抽取删除掉，所以有了<code>惰性删除</code>，当使用获取key操作时，<code>redis</code>会检查key是否过期，如果过期了就删除掉不会返回任何东西</li></ul></li></ul><p><strong>但是如果某个key一直没有获取操作或者被定期删除随机抽取到，那么也会堆积大量key在内存里，所以有了内存淘汰机制</strong></p><h4 id="内存淘汰机制"><a href="#内存淘汰机制" class="headerlink" title="内存淘汰机制"></a>内存淘汰机制</h4><p><strong>redis 内存淘汰机制有以下几个：</strong></p><ul><li><code>noeviction</code>: 当内存不足以容纳新写入数据时，新写入操作会报错，这个一般没人用吧，实在是太恶心了。</li><li><code>allkeys-lru</code>：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最常用的）。</li><li><code>allkeys-random</code>：当内存不足以容纳新写入数据时，在键空间中，随机移除某个 key，这个一般没人用吧，为啥要随机，肯定是把最近最少使用的 key 给干掉啊。</li><li><code>volatile-lru</code>：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的 key（这个一般不太合适）。</li><li><code>volatile-random</code>：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个 key。</li><li><code>volatile-ttl</code>：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的 key 优先移除。</li></ul><h3 id="实战演练"><a href="#实战演练" class="headerlink" title="实战演练"></a>实战演练</h3><blockquote><p>我在公司负责过一个直播项目，主播会提前预约一个直播间，然后把直播间通过社交软件分享出去吸引流量；如果预约时间过了10分钟还没有来开播，那么会删除直播间 + 七牛直播云关闭<code>Stream</code> + <code>imId</code>（当然，到了预约时间提前10分钟会push给主播提醒他开播，这些跟本文无关就不提了 )。</p></blockquote><h4 id="解决方案选择"><a href="#解决方案选择" class="headerlink" title="解决方案选择"></a>解决方案选择</h4><ol><li>使用<code>MQ</code>的延时消息来做，但是当时研究发现<code>RocketMQ</code>只支持指定的延时级别1s, 2s, … , 2h，没办法指定到具体的时间，其实这一点也能想到，RocketMQ作为一个高吞吐，低延时的消息队列，不设计这种具体到指定时间的延时消息也情有可原，因为这样就要在对消息排序上做大量处理，会极大地影响性能。于是 ，此方案不予采用。</li><li>采用定时任务来做，但是这样会很纠结这个定时任务的轮询时间，5分钟1次？2分钟1次？这样也没办法指定到具体时间，思来想去总觉得这个方案不太优雅，嗯，弃用。</li><li>自己实现一个时间轮？嗯，因为之前自己实现过一个时间轮，就拷贝到项目中使用，效果还不错，但是由于任务是放在内存中的，项目一重启，或者其他原因故障会导致任务丢失。这样一来那些空无一人的直播间挂在我们的直播首页也不太美观。于是考虑到要对任务做持久化，嗯，这样复杂度越来越高，而且还要新增业务表；于是乎，此方案也不采用。</li><li>最后是采用监听<code>redis</code> 的key过期事件来处理这个问题：将直播间<code>roomId:</code>做为key前缀，<code>expireTime</code> = 预约开播时间 + 10分钟 - 当前时间。当监听到指定key过期时，调用指定业务方法区处理。这样一来不需要引入额外的中间件，编码复杂度低，处理时间十分精确，完美地解决问题。</li></ol><h4 id="代码示例"><a href="#代码示例" class="headerlink" title="代码示例"></a>代码示例</h4><ul><li><strong><font style="color:red;">注意：需要开启<code>Redis</code> key 过期提醒，在<code>redis.conf</code>中加入<code>notify-keyspace-events Ex</code>配置 </font></strong></li></ul><h5 id="配置类"><a href="#配置类" class="headerlink" title="配置类"></a>配置类</h5><pre><code class="java">@Configurationpublic class RedisConfig {    @Bean    public RedisTemplate&lt;String, Object&gt; redisTemplate(RedisConnectionFactory factory) {        RedisTemplate&lt;String, Object&gt; template = new RedisTemplate&lt;&gt;();        template.setConnectionFactory(factory);        // 设置key的序列化方式        template.setKeySerializer(RedisSerializer.string());        // 设置value的序列化方式        template.setValueSerializer(RedisSerializer.json());        // 设置hash的key的序列化方式        template.setHashKeySerializer(RedisSerializer.string());        // 设置hash的value的序列化方式        template.setHashValueSerializer(RedisSerializer.json());        template.afterPropertiesSet();        return template;    }    /**     * 将redis消息监听器注册为一个bean     * @param connectionFactory 链接工厂     * @return RedisMessageListenerContainer     */    @Bean    public RedisMessageListenerContainer container(RedisConnectionFactory connectionFactory) {        RedisMessageListenerContainer container = new RedisMessageListenerContainer();        container.setConnectionFactory(connectionFactory);        return container;    }}</code></pre><h5 id="key过期监听类"><a href="#key过期监听类" class="headerlink" title="key过期监听类"></a>key过期监听类</h5><pre><code class="java">@Slf4j@Componentpublic class RedisKeyExpirationListener extends KeyExpirationEventMessageListener {    public RedisKeyExpirationListener(RedisMessageListenerContainer listenerContainer) {        super(listenerContainer);    }    @Override    public void onMessage(Message message, byte[] pattern) {        //获取失效的key, 进行对应的业务处理        String expiredKey = message.toString();        //取redis前缀符合的进行乡音处理        if (expiredKey.startsWith(RedisKeyConstant.LIVE_ROOM_CLOSE)) {            log.info(&quot;【这里进行对应的业务处理】, 业务key = {}过期&quot;, expiredKey);        }    }}</code></pre><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><blockquote><p>​        其实，我这里的实战演练中的业务对时间点选择不是那么敏感，采用定时任务去处理，稍微晚那么几分钟关闭过期未及时开播的直播间也未尝不可，只是我个人是觉得监听redis key过期的方案更优雅，实现也简单罢了。其实这种方案适合很多种场景，比如订单30分钟超时未支付取消订单也非常适合使用。在未来我也会对自己所知所学多做总结，希望能做到温故知新，在日常学习中提升技术广度，在工作中践行技术深度，自我勉励！</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>redis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>LeetCode题解-102.二叉树的层序遍历</title>
    <link href="/2020/05/14/LeetCode%E9%A2%98%E8%A7%A3-102.%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B1%82%E5%BA%8F%E9%81%8D%E5%8E%86/"/>
    <url>/2020/05/14/LeetCode%E9%A2%98%E8%A7%A3-102.%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B1%82%E5%BA%8F%E9%81%8D%E5%8E%86/</url>
    
    <content type="html"><![CDATA[<h3 id=""><a href="#" class="headerlink" title=""></a></h3><h3 id="102-二叉树的层序遍历"><a href="#102-二叉树的层序遍历" class="headerlink" title="102.二叉树的层序遍历"></a>102.二叉树的层序遍历</h3><ul><li>给你一个二叉树，请你返回其按 层序遍历 得到的节点值。 （即逐层地，从左到右访问所有节点）。</li></ul><pre><code class="markdown">示例：二叉树：[3,9,20,null,null,15,7],    3   / \  9  20    /  \   15   7返回其层次遍历结果：[  [3],  [9,20],  [15,7]]</code></pre><h4 id="深度度优先遍历-DFS"><a href="#深度度优先遍历-DFS" class="headerlink" title="深度度优先遍历-DFS"></a>深度度优先遍历-DFS</h4><pre><code class="java">class Solution {    List&lt;List&lt;Integer&gt;&gt; depthList = new ArrayList&lt;&gt;();    /**     * 解法一: 采用深度优先遍历     * @param root 根节点     * @return List&lt;List&lt;Integer&gt;&gt;     */    public List&lt;List&lt;Integer&gt;&gt; levelOrderUseDFS(TreeNode root) {        if (null == root) {            return depthList;        }        recursive(root, 0);        return depthList;    }    public void recursive(TreeNode node, int depth) {        if (depthList.size() == depth) {            //这里使用链表，不需要扩容            depthList.add(new LinkedList&lt;&gt;());        }        depthList.get(depth).add(node.val);        if (null != node.left) {            recursive(node.left, depth + 1);        }        if (null != node.right) {            recursive(node.right, depth + 1);        }    }}</code></pre><h4 id="广度优先遍历-BFS"><a href="#广度优先遍历-BFS" class="headerlink" title="广度优先遍历-BFS"></a>广度优先遍历-BFS</h4><pre><code class="java">     /**     * 解法二: 采用深度优先遍历     * @param root 根节点     * @return List&lt;List&lt;Integer&gt;&gt;     */    public List&lt;List&lt;Integer&gt;&gt; levelOrderUseBFS(TreeNode root) {        List&lt;List&lt;Integer&gt;&gt; res = new ArrayList&lt;&gt;();        if (null == root) {            return res;        }        Queue&lt;TreeNode&gt; queue = new LinkedList&lt;&gt;();        queue.offer(root);        while (!queue.isEmpty()) {            int size = queue.size();            List&lt;Integer&gt; list = new LinkedList&lt;&gt;();            //内循环取出位于二叉树同一层的元素            for (int i = 0; i &lt; size; i++) {                TreeNode cur = queue.remove();                list.add(cur.val);                if (null != cur.left) {                    queue.add(cur.left);                }                if (null != cur.right) {                    queue.add(cur.right);                }            }            res.add(list);        }        return res;    }</code></pre>]]></content>
    
    
    <categories>
      
      <category>LeetCode</category>
      
    </categories>
    
    
    <tags>
      
      <tag>LeetCode</tag>
      
      <tag>数据结构</tag>
      
      <tag>算法</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hasor DataWay 简化后台开发</title>
    <link href="/2020/05/01/Hasor%20DataWay%20%E7%AE%80%E5%8C%96%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/"/>
    <url>/2020/05/01/Hasor%20DataWay%20%E7%AE%80%E5%8C%96%E5%90%8E%E5%8F%B0%E5%BC%80%E5%8F%91/</url>
    
    <content type="html"><![CDATA[<h3 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h3><blockquote><p>五一小长假终于来了，在放假之前我就做好打算，在家宅着与代码为伴，学一些自己感兴趣的东西。偶然看见一个介绍Hasor Dataway的文章，能够简化后端繁琐的开发，抛弃controller，service，mapper，dao等繁琐的工作，直接将数据更直接的展示出来。所以我也就只是介绍快速搭建一个开发环境，以及一些基本的使用，不求甚解，只是纯粹出于个人的兴趣，以后有时间说不定再研究一下。</p></blockquote><p><code>Dataway文档地址</code>：<a href="https://www.hasor.net/web/index.html" target="_blank" rel="noopener">https://www.hasor.net/web/index.html</a></p><p><code>Hasor的仓库地址</code>:    <a href="https://gitee.com/zycgit/hasor.git" target="_blank" rel="noopener">https://gitee.com/zycgit/hasor.git</a></p><h3 id="快速入门"><a href="#快速入门" class="headerlink" title="快速入门"></a>快速入门</h3><h4 id="pom-xml"><a href="#pom-xml" class="headerlink" title="pom.xml"></a>pom.xml</h4><pre><code class="xml">&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;mysql&lt;/groupId&gt;    &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;    &lt;scope&gt;runtime&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;    &lt;artifactId&gt;spring-boot-starter-jdbc&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!-- 引入依赖 --&gt;&lt;dependency&gt;    &lt;groupId&gt;net.hasor&lt;/groupId&gt;    &lt;artifactId&gt;hasor-spring&lt;/artifactId&gt;    &lt;version&gt;4.1.4&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;    &lt;groupId&gt;net.hasor&lt;/groupId&gt;    &lt;artifactId&gt;hasor-dataway&lt;/artifactId&gt;    &lt;version&gt;4.1.4&lt;/version&gt;&lt;/dependency&gt;</code></pre><h4 id="application-yml"><a href="#application-yml" class="headerlink" title="application.yml"></a>application.yml</h4><pre><code class="yaml"># 配置我的连接的通用属性alicloud:  host: xxx  username: xxx  password: xxxspring:  datasource:    #    最好用的数据源，速度最快 HikariCP    driver-class-name: com.mysql.cj.jdbc.Driver    url: jdbc:mysql://${alicloud.host}:3306/community    username: ${alicloud.username}    password: ${alicloud.password}# 启用 Dataway 功能（默认不启用）HASOR_DATAQL_DATAWAY: true  # 开启 ui 管理功能（注意生产环境必须要设置为 false，否则会造成严重的生产安全事故）HASOR_DATAQL_DATAWAY_ADMIN: true  # （可选）API工作路径HASOR_DATAQL_DATAWAY_API_URL: /api/  # （可选）ui 的工作路径，只有开启 ui 管理功能后才有效HASOR_DATAQL_DATAWAY_UI_URL: /interface-ui/</code></pre><h4 id="初始化sql"><a href="#初始化sql" class="headerlink" title="初始化sql"></a>初始化sql</h4><ul><li><code>sql</code>在<code>hasor-dataway</code>的<code>META-INF/hasor-framework</code>下可以找到</li></ul><pre><code class="mysql">CREATE TABLE `interface_info` (    `api_id`          int(11)      NOT NULL AUTO_INCREMENT   COMMENT &#39;ID&#39;,    `api_method`      varchar(12)  NOT NULL                  COMMENT &#39;HttpMethod：GET、PUT、POST&#39;,    `api_path`        varchar(512) NOT NULL                  COMMENT &#39;拦截路径&#39;,    `api_status`      int(2)       NOT NULL                  COMMENT &#39;状态：0草稿，1发布，2有变更，3禁用&#39;,    `api_comment`     varchar(255)     NULL                  COMMENT &#39;注释&#39;,    `api_type`        varchar(24)  NOT NULL                  COMMENT &#39;脚本类型：SQL、DataQL&#39;,    `api_script`      mediumtext   NOT NULL                  COMMENT &#39;查询脚本：xxxxxxx&#39;,    `api_schema`      mediumtext       NULL                  COMMENT &#39;接口的请求/响应数据结构&#39;,    `api_sample`      mediumtext       NULL                  COMMENT &#39;请求/响应/请求头样本数据&#39;,    `api_create_time` datetime     DEFAULT CURRENT_TIMESTAMP COMMENT &#39;创建时间&#39;,    `api_gmt_time`    datetime     DEFAULT CURRENT_TIMESTAMP COMMENT &#39;修改时间&#39;,    PRIMARY KEY (`api_id`)) ENGINE=InnoDB AUTO_INCREMENT=0 DEFAULT CHARSET=utf8mb4 COMMENT=&#39;Dataway 中的API&#39;;CREATE TABLE `interface_release` (    `pub_id`          int(11)      NOT NULL AUTO_INCREMENT   COMMENT &#39;Publish ID&#39;,    `pub_api_id`      int(11)      NOT NULL                  COMMENT &#39;所属API ID&#39;,    `pub_method`      varchar(12)  NOT NULL                  COMMENT &#39;HttpMethod：GET、PUT、POST&#39;,    `pub_path`        varchar(512) NOT NULL                  COMMENT &#39;拦截路径&#39;,    `pub_status`      int(2)       NOT NULL                  COMMENT &#39;状态：0有效，1无效（可能被下线）&#39;,    `pub_type`        varchar(24)  NOT NULL                  COMMENT &#39;脚本类型：SQL、DataQL&#39;,    `pub_script`      mediumtext   NOT NULL                  COMMENT &#39;查询脚本：xxxxxxx&#39;,    `pub_script_ori`  mediumtext   NOT NULL                  COMMENT &#39;原始查询脚本，仅当类型为SQL时不同&#39;,    `pub_schema`      mediumtext       NULL                  COMMENT &#39;接口的请求/响应数据结构&#39;,    `pub_sample`      mediumtext       NULL                  COMMENT &#39;请求/响应/请求头样本数据&#39;,    `pub_release_time`datetime     DEFAULT CURRENT_TIMESTAMP COMMENT &#39;发布时间（下线不更新）&#39;,    PRIMARY KEY (`pub_id`)) ENGINE=InnoDB AUTO_INCREMENT=0 DEFAULT CHARSET=utf8mb4 COMMENT=&#39;Dataway API 发布历史。&#39;;create index idx_interface_release on interface_release (pub_api_id);</code></pre><h4 id="将Datasource注入Hasor容器"><a href="#将Datasource注入Hasor容器" class="headerlink" title="将Datasource注入Hasor容器"></a>将Datasource注入Hasor容器</h4><ul><li>在项目目录下建一个<code>hasor目录</code></li></ul><pre><code class="java">package xxx.hasor;import net.hasor.core.ApiBinder;import net.hasor.core.DimModule;import net.hasor.db.JdbcModule;import net.hasor.db.Level;import net.hasor.spring.SpringModule;import org.springframework.stereotype.Component;import javax.annotation.Resource;import javax.sql.DataSource;/** * @author : eyestarrysky * @date : Created in 2020/5/1 */@DimModule@Componentpublic class HasorModule implements SpringModule {    @Resource    private DataSource dataSource;    @Override    public void loadModule(ApiBinder apiBinder) throws Throwable {        apiBinder.installModule(new JdbcModule(Level.Full, this.dataSource));    }}</code></pre><h4 id="SpringBoot启动类开启Hasor注解"><a href="#SpringBoot启动类开启Hasor注解" class="headerlink" title="SpringBoot启动类开启Hasor注解"></a>SpringBoot启动类开启Hasor注解</h4><pre><code class="java">package xxx;import net.hasor.spring.boot.EnableHasor;import net.hasor.spring.boot.EnableHasorWeb;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;@EnableHasor@EnableHasorWeb@SpringBootApplicationpublic class DatawayApplication {    public static void main(String[] args) {        SpringApplication.run(DatawayApplication.class, args);    }}</code></pre><h4 id="项目启动"><a href="#项目启动" class="headerlink" title="项目启动"></a>项目启动</h4><pre><code class="verilog"> _    _                        ____              _| |  | |                      |  _ \            | || |__| | __ _ ___  ___  _ __  | |_) | ___   ___ | |_|  __  |/ _` / __|/ _ \| &#39;__| |  _ &lt; / _ \ / _ \| __|| |  | | (_| \__ \ (_) | |    | |_) | (_) | (_) | |_|_|  |_|\__,_|___/\___/|_|    |____/ \___/ \___/ \__|</code></pre><ul><li>项目启动成功，访问<code>http://localhost:8080/interface-ui/</code>即可</li></ul><h3 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h3><ul><li>接口面板</li></ul><p><img src="http://qiniu.eyestarrysky.top/dataway-console.png" alt="找不到"></p><ul><li>新增接口，右边几个按钮分别为<code>save</code>，<code>execute</code>, <code>test</code>, <code>publish</code></li></ul><p><img src="http://qiniu.eyestarrysky.top/dataway-new-interface.png" alt="找不到"></p>]]></content>
    
    
    <categories>
      
      <category>java</category>
      
    </categories>
    
    
    <tags>
      
      <tag>DataQL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>使用jetcache来操作缓存</title>
    <link href="/2020/04/27/%E4%BD%BF%E7%94%A8jetcache%E6%9D%A5%E6%93%8D%E4%BD%9C%E7%BC%93%E5%AD%98/"/>
    <url>/2020/04/27/%E4%BD%BF%E7%94%A8jetcache%E6%9D%A5%E6%93%8D%E4%BD%9C%E7%BC%93%E5%AD%98/</url>
    
    <content type="html"><![CDATA[<h3 id="Jetcache前言"><a href="#Jetcache前言" class="headerlink" title="Jetcache前言"></a>Jetcache前言</h3><ul><li><code>git</code>地址:  <a href="https://github.com/alibaba/jetcache/" target="_blank" rel="noopener">https://github.com/alibaba/jetcache/</a></li></ul><p>​        <strong>因为之前项目的原因接触过jecache，但是没有好好整理，今天闲下来，悉心整理了下，并看了下文档，学了下自动刷新缓存，感觉这个挺适合用来更新首页轮播图，通栏的。</strong></p><h3 id="基本配置（Spring-Boot"><a href="#基本配置（Spring-Boot" class="headerlink" title="基本配置（Spring Boot)"></a>基本配置（Spring Boot)</h3><h4 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h4><h5 id="pom-xml"><a href="#pom-xml" class="headerlink" title="pom.xml"></a>pom.xml</h5><pre><code class="xml">&lt;!-- jetCache  --&gt;&lt;dependency&gt;    &lt;groupId&gt;com.alicp.jetcache&lt;/groupId&gt;    &lt;artifactId&gt;jetcache-starter-redis&lt;/artifactId&gt;    &lt;version&gt;2.6.0&lt;/version&gt;&lt;/dependency&gt;</code></pre><h5 id="application-yml"><a href="#application-yml" class="headerlink" title="application.yml"></a>application.yml</h5><pre><code class="yml">#jetcache# @see com.alicp.jetcache.autoconfigure.JetCachePropertiesjetcache:  # 统计间隔，默认0：表示不统计  statIntervalMinutes: 1  # areaName是否作为缓存key前缀，默认True  areaInCacheName: false  local:    default:      # 已支持可选：linkedhashmap、caffeine      type: linkedhashmap      # key转换器的全局配置，当前只有：fastjson, @see com.alicp.jetcache.support.FastjsonKeyConvertor      keyConvertor: fastjson      # 每个缓存实例的最大元素的全局配置，仅local类型的缓存需要指定      limit: 100      # jetcache2.2以上，以毫秒为单位，指定多长时间没有访问，就让缓存失效，当前只有本地缓存支持。0表示不使用这个功能，指定30秒后失效      expireAfterAccessInMillis: 30000  remote:    default:      type: redis      keyConvertor: fastjson      valueEncoder: java      valueDecoder: java      poolConfig:        minIdle: 5        maxIdle: 20        maxTotal: 50      host: ${redis.host}      port: 6379      password: ${redis.password}</code></pre><h5 id="启动类"><a href="#启动类" class="headerlink" title="启动类"></a>启动类</h5><pre><code class="java">@SpringBootApplication@EnableMethodCache(basePackages = &quot;com.company.mypackagee&quot;)@EnableCreateCacheAnnotationpublic class Application extends SpringBootServletInitializer {    public static void main(String[] args) {        SpringApplication.run(Application.class);    }}</code></pre><h3 id="基本使用"><a href="#基本使用" class="headerlink" title="基本使用"></a>基本使用</h3><ul><li><p>下面例子以操作<code>User</code>为例<br><code>user.java</code></p><pre><code class="java">@TableName(value = &quot;user&quot;)@Datapublic class User implements Serializable {    private static final long serialVersionUID = 738881519595997996L;    /**主键**/    @NotNull(message = &quot;主键不能为空&quot;)    private Long id;    /**姓名**/    @NotBlank(message = &quot;名字不能为空&quot;)    @Length(min = 1, message = &quot;名字至少1个字&quot;)    private String name;    /**手机号**/    @NotBlank(message = &quot;手机号不能为空&quot;)    @Size(max = 11, message = &quot;手机号最长11位&quot;)    @Pattern(regexp = &quot;^1\\d+$&quot;, message = &quot;手机号格式不正确&quot;)    private String phone;    /**电子邮件**/    @NotBlank(message = &quot;邮箱不能为空&quot;)    @Email(message = &quot;电子邮件格式不正确&quot;)    @Length(max = 30, message = &quot;邮箱长度不能超过30!&quot;)    private String email;    /**自我介绍**/    private String aboutme;    /**加密密码**/    private String passwd;    /**头像图片**/    private String avatar;    /**1:普通用户，2:房产经纪人**/    private Integer type;    /**创建时间**/    private Date createTime;    /**是否启用,1启用，0停用**/    private Integer enable;    /**所属经纪机构**/    private Integer agencyId;}</code></pre></li></ul><h4 id="基于注解实现方法缓存"><a href="#基于注解实现方法缓存" class="headerlink" title="基于注解实现方法缓存"></a>基于注解实现方法缓存</h4><h5 id="Cached：创建缓存"><a href="#Cached：创建缓存" class="headerlink" title="@Cached：创建缓存"></a>@Cached：创建缓存</h5><pre><code class="java">/** * 基于注解创建缓存 * 缓存在 Remote 的 Redis，也可以配置成 both 开启两级缓存 */@Cached(name = CACHE_NAME, key = &quot;#userId&quot;, cacheType = CacheType.LOCAL, expire = 5 * 60)@CacheRefresh(refresh = 60)public UserVO findUserById(Long userId) {    User user = userMapper.selectOne(queryWrapper);    //.....................}</code></pre><h5 id="CacheInvalidate：删除缓存"><a href="#CacheInvalidate：删除缓存" class="headerlink" title="@CacheInvalidate：删除缓存"></a>@CacheInvalidate：删除缓存</h5><pre><code class="java">@CacheInvalidate(name = CACHE_NAME, key = &quot;#userId&quot;)@Transactional(rollbackFor = Exception.class)public int deleteUserById(Long userId) {    User user = new User();    user.setId(userId);    user.setEnable(0);    UpdateWrapper&lt;User&gt; updateWrapper = new UpdateWrapper&lt;&gt;();    updateWrapper.lambda().eq(User::getId, userId).eq(User::getEnable, 1);    return userMapper.update(user, updateWrapper);}</code></pre><h5 id="CacheUpdate：更新缓存"><a href="#CacheUpdate：更新缓存" class="headerlink" title="@CacheUpdate：更新缓存"></a>@CacheUpdate：更新缓存</h5><pre><code class="java">/** * 更新用户 * @param user 用户 * @return int */@CacheUpdate(name = CACHE_NAME, key = &quot;#user.id&quot;, value = &quot;#user&quot;)public int updateUser(User user) {    log.info(&quot;【UserUpdate操作】, user = {}&quot;, JSON.toJSONString(user));    return userMapper.updateById(user);}</code></pre><h4 id="基于-CreateCache注解创建Cache实例"><a href="#基于-CreateCache注解创建Cache实例" class="headerlink" title="基于@CreateCache注解创建Cache实例"></a>基于@CreateCache注解创建Cache实例</h4><h5 id="CreateCache"><a href="#CreateCache" class="headerlink" title="@CreateCache"></a>@CreateCache</h5><pre><code class="java">/** * 使用 @CreateCache 注解创建Cache实例; * 未定义默认值的参数，将使用yml中指定的全局配置; * 缓存在 Local，也可以配置成 both 开启两级缓存 */@CreateCache(name = CACHE_NAME, expire = 5 * 60, localLimit = 10, cacheType = CacheType.LOCAL)private Cache&lt;Long, UserVO&gt; userCache;</code></pre><h5 id="查询缓存"><a href="#查询缓存" class="headerlink" title="查询缓存"></a>查询缓存</h5><pre><code class="java">public UserVO getUserByIdAndCreateCache(Long userId) {    //根据id从缓存中取    UserVO userVO = userCache.get(userId);    log.info(&quot;userCreateCache get {} res {}&quot;, userId, userCache);    if (Objects.isNull(userVO)) {        User user = userMapper.selectById(userId);        if (Objects.nonNull(user)) {            userVO = new UserVO();            BeanUtils.copyProperties(user, userVO);            //如果不存在就放入缓存中            boolean res = userCache.putIfAbsent(user.getId(), userVO);            log.info(&quot;userCreateCache putIfAbsent {} res {}&quot;, userId, res);        }    }    return userVO;}</code></pre><h5 id="删除缓存"><a href="#删除缓存" class="headerlink" title="删除缓存"></a>删除缓存</h5><pre><code class="java">@Transactional(rollbackFor = Exception.class)public int deleteUserByIdAndCreateCache(Long userId) {    User user = new User();    UpdateWrapper&lt;User&gt; updateWrapper = new UpdateWrapper&lt;&gt;();    updateWrapper.lambda().eq(User::getId, userId).eq(User::getEnable, 1);    user.setId(userId);    user.setEnable(0);    int result = userMapper.update(user, updateWrapper);    if (result &gt; 0) {        //根据key = userId删除缓存        boolean deleteResult = userCache.remove(userId);        log.info(&quot;同步删除缓存, userId = {}, res = {}&quot;, userId, deleteResult);    }    return result;}</code></pre>]]></content>
    
    
    <categories>
      
      <category>缓存</category>
      
    </categories>
    
    
    <tags>
      
      <tag>jetcache</tag>
      
      <tag>缓存</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>利用github和hexo快速搭建个人博客</title>
    <link href="/2020/04/17/%E5%88%A9%E7%94%A8github%E5%92%8Chexo%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"/>
    <url>/2020/04/17/%E5%88%A9%E7%94%A8github%E5%92%8Chexo%E5%BF%AB%E9%80%9F%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/</url>
    
    <content type="html"><![CDATA[<h3 id="一、准备工作"><a href="#一、准备工作" class="headerlink" title="一、准备工作"></a>一、准备工作</h3><h4 id="安装git"><a href="#安装git" class="headerlink" title="安装git"></a>安装git</h4><p><code>git</code>下载地址：<code>http://gitforwindows.org</code></p><h4 id="安装node-js"><a href="#安装node-js" class="headerlink" title="安装node.js"></a>安装node.js</h4><p> <code>node.js</code> 下载地址：<code>http://nodejs.org/en/</code> </p><h3 id="二、本地搭建"><a href="#二、本地搭建" class="headerlink" title="二、本地搭建"></a>二、本地搭建</h3><ul><li><p>选择一个文件夹建一个目录<code>blog</code>存放博客相关文件，文件夹内右键打开<code>git bash here</code>，在窗口中执行以下所有命令</p></li><li><p>用<code>npm</code>安装<code>hexo</code>，由于国内网络高“墙”深院，避免安装缓慢或失败，这里切换阿里的<code>NPM</code>镜像，没办法只能采用迂回战术了。</p></li></ul><pre><code class="sh">$ npm install -g cnpm --registry=http://registry.npm.taobao.org</code></pre><p>用 <code>cnpm</code> 安装 <code>hexo</code></p><pre><code class="sh">$ cnpm install -g hexo-cli$ cnpm install hexo --save##检查hexo是否安装成功$ hexo -v</code></pre><ul><li>在<code>blog</code>文件夹建一个<code>hexo</code>文件存放博客，进入也打开<code>git bash here</code></li></ul><pre><code class="sh">$ hexo init</code></pre><p>初始化成功后，<code>hexo文件</code>夹内会出现如下的文件：</p><p><code>node_modules</code>: 依赖包<br><code>public</code>：存放生成的页面<br><code>scaffolds</code>：生成文章的一些模板<br><code>source</code>：用来存放你的文章<br><code>themes</code>：放下下载的主题<br><code>_config.yml:</code> 博客的核心配置文件（设置主体、标题等属性）</p><ul><li><p>接着需要执行一下<code>cnpm install</code>命令，要不下边的启动会提示命令不合法。</p></li><li><p>最后使用<code>hexo s -g</code>启动安装好的<code>hexo</code></p></li></ul><h3 id="三、托管至GitHub"><a href="#三、托管至GitHub" class="headerlink" title="三、托管至GitHub"></a>三、托管至GitHub</h3><ul><li><p>建立一个仓库，名称为<code>xxx.github.io</code></p></li><li><p>配置<code>_config.xml</code>文件，添加<code>GitHub</code>地址</p></li></ul><pre><code class="yml">deploy:  type: git  repo: https://github.com/xxx/xxx.github.io.git  branch: master</code></pre><ul><li>安装部署命令<code>deploy-git</code> ，这样你才能用命令部署到<code>GitHub</code></li></ul><pre><code class="sh">$ cnpm install hexo-deployer-git  --save</code></pre><ul><li>安装好后，依次执行下列命令，提交本地<code>hexo</code>文件到<code>GitHub</code></li></ul><pre><code class="sh">$ hexo clean$ hexo generate$ hexo deploy</code></pre><ul><li>最后访问<code>https://xxx.github.io.git</code>即可</li></ul><h3 id="四、选择自己喜欢的主题"><a href="#四、选择自己喜欢的主题" class="headerlink" title="四、选择自己喜欢的主题"></a>四、选择自己喜欢的主题</h3><ul><li><p>到<code>http://hexo.io/themes/</code>下载主题，<code>git clone</code>到本地</p><p><code>git clone https://github.com/iissnan/hexo-theme-next</code></p></li><li><p>修改<code>hexo</code>文件夹下的<code>_config.yml</code>文件中的<code>theme</code>属性</p></li></ul><pre><code class="yml">theme: hexo-theme-next</code></pre><ul><li>再次打包上传即可<pre><code class="sh">$ hexo clean$ hexo generate$ hexo deploy</code></pre></li></ul><h3 id="五、Hexo基本操作"><a href="#五、Hexo基本操作" class="headerlink" title="五、Hexo基本操作"></a>五、Hexo基本操作</h3><p>博客文章都放在<code>source\_post</code>目录下</p>]]></content>
    
    
    <categories>
      
      <category>hexo</category>
      
      <category>建站</category>
      
    </categories>
    
    
    <tags>
      
      <tag>建站</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
